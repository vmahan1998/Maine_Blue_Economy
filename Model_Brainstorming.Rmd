---
title: "Model Structure Brainstorming"
author: "Vanessa Quintana"
date: "`r Sys.Date()`"
output: html_document
---

# Brainstorming Model Inputs
- landings by pound and by value from 1950-2019 (overall abundance and economic value)
- lobster landings by county for pound and value (ties abundance to reginal economic importance)
- 

## Input Data

### DMR Landings for Species 1950-2019
```{r}
rm(list = ls())  # Clears all objects from the environment

# Load necessary libraries
library(tidyverse)
library(randomForest)
library(ggplot2)
library(dplyr)
library(lubridate)
library(tidyr)
library(caret)
library(tseries)
library(Metrics)
library(zoo)
library(stringdist)

# Load historical data (1950-2019)
landings <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/MaineDMR_Landings_Time_Series_Data_2025-03-10.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(landings)
str(landings)
summary(landings)

# Market Price per Kilogram
landings$market_price_per_Kg <- landings$total_value / landings$total_weight
```

### Lobster Landings by County in pounds and value
```{r}
# Load historical data (1950-2019)
lobster_County <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/LobByCntyMoZone.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(lobster_County)
str(lobster_County)
summary(lobster_County)
```


### NOAA Tides and Currents Water Levels Monthly Eastport, Portland, Bar Harbor, Maine.
```{r}
# Load Historical Water Level Data

# Load Portland, ME Water Level Data
portland <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Portland_Historic_Water_Levels.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(portland)
str(portland)
summary(portland)

# Load Portland, ME Water Level Data
eastport <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Eastport_Historic_Water_Levels.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(eastport)
str(eastport)
summary(eastport)

# Load Portland, ME Water Level Data
barharbor <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Bar_Harbor_Historic_Water_Levels.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(barharbor)
str(barharbor)
summary(barharbor)

# Function to clean and process water level data
clean_water_levels <- function(df, station_name) {
  df <- df %>%
    dplyr::mutate(Date = as.Date(Date, format="%Y/%m/%d"),
           Year = year(Date)) %>%
    dplyr::select(Year, MSL..ft.) %>%
    dplyr::rename(Mean_Sea_Level_ft = MSL..ft.) %>%
    dplyr::group_by(Year) %>%
    dplyr::summarize(Mean_Sea_Level_ft = mean(Mean_Sea_Level_ft, na.rm = TRUE)) %>%
    dplyr::mutate(Station = station_name)
  
  return(df)
}

# Apply function to each station
portland_clean <- clean_water_levels(portland, "Portland")
eastport_clean <- clean_water_levels(eastport, "Eastport")
barharbor_clean <- clean_water_levels(barharbor, "Bar Harbor")

# Combine all stations
water_levels <- bind_rows(portland_clean, eastport_clean, barharbor_clean)

# Convert feet to meters (1 ft = 0.3048 m)
water_levels <- water_levels %>%
  mutate(Mean_Sea_Level_m = Mean_Sea_Level_ft * 0.3048)

# Preview cleaned water levels
head(water_levels)
```

### NOAA Oceanic Nino Index (ONI)
```{r}
# If the data is tab-separated, use:
enso_data <- read.table("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/NOAA_ONI.txt", header = TRUE, sep = "", stringsAsFactors = FALSE)

# Convert to numeric
enso_data$Anomaly <- as.numeric(enso_data$ANOM)

# Categorize ENSO Phases
enso_data <- enso_data %>%
  mutate(ENSO_Phase = case_when(
    Anomaly > 0.5 ~ "El Niño",
    Anomaly < -0.5 ~ "La Niña",
    TRUE ~ "Neutral"
  ))

# Inspect data
head(enso_data)
str(enso_data)
summary(enso_data)

```

### NOAA North Atlantic Oscillation Index
```{r}
# If the data is tab-separated, use:
NAO_data <- read.table("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/NAO_Index_NOAA.txt", header = TRUE, stringsAsFactors = FALSE)

# Convert row names into an actual column
NAO_data <- NAO_data %>%
  rownames_to_column(var = "Year")  # Moves row names to a column called "Year"

# Convert Year to numeric
NAO_data$Year <- as.numeric(NAO_data$Year)

NAO_long <- NAO_data %>%
  pivot_longer(cols = -Year, names_to = "Month", values_to = "NAO_Index") %>%
  drop_na

# Inspect data
head(NAO_data)
str(NAO_data)
summary(NAO_data)

```

### NOAA Stock Assessment Data
```{r}
# Load Stock Assessment Data
stocks <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Assessment_TimeSeries_Data.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Save original column names to extract species names
original_colnames <- colnames(stocks)

# Extract species names (taking first two words, assuming "Atlantic cod" or "White hake" style)
species_names <- sub("^(\\w+\\.\\w+).*", "\\1", original_colnames)
species_names <- gsub("\\.", " ", species_names)  # Replace dots with spaces for readability

# Extract stock assessment variable names (everything after first "..")
stock_variables <- sub("^.*?\\.\\.\\.", "", original_colnames)

# Rename columns with extracted species and variable names
colnames(stocks) <- paste(species_names, stock_variables, sep = "_")

# Combine species names with row 1 and row 4 for new column names
new_colnames <- paste(species_names, stocks[3, ], stocks[6, ], sep = "_")

# Assign new column names
colnames(stocks) <- new_colnames

# Save the first column's name before removing it
year_colname <- colnames(stocks)[1]

# Remove the first column (year column temporarily)
stocks <- stocks[, -1]  

# Remove rows 1, 2, and 4 (including extra metadata rows)
stocks <- stocks[-c(1:7), ]

# Reassign the saved year column name to the first column
colnames(stocks)[1] <- year_colname

# Identify rows where all columns except the first are empty
stocks <- stocks[-c(1:20), ]

stocks <- stocks %>%
  mutate(across(everything(), ~ as.numeric(.)))

# Reset row indices
rownames(stocks) <- NULL

# Function to interpolate numeric columns
interpolate_numeric <- function(x) {
  if (is.numeric(x)) {
    return(na.approx(x, rule = 2))  # Linear interpolation
  } else {
    return(x)  # Return as is if not numeric
  }
}

# Apply interpolation to numeric columns
interpolated_stocks <- stocks %>%
  mutate(across(where(is.numeric), interpolate_numeric))

# Manually clean known variable names for clarity
stock_variables <- str_replace_all(stock_variables, "Reported Catch - Total \\(Mean\\)", "Total Catch")
stock_variables <- str_replace_all(stock_variables, "Total F, Ages 5-7 \\(Mean\\)", "Mean F, Ages 5-7")
stock_variables <- str_replace_all(stock_variables, "Mature Biomass \\(Mean\\)", "Mature Biomass")
stock_variables <- str_replace_all(stock_variables, "Abundance, Age 1 \\(Mean\\)", "Age 1 Abundance")
stock_variables <- str_replace_all(stock_variables, "Catch - Landings \\+ Commercial Discards", "Total Landings + Discards")

# Extract year from Variable (assuming yyyy_Total Catch format)
stocks_long <- interpolated_stocks %>%
  pivot_longer(cols = -1, names_to = "Stock_Variable", values_to = "Value") %>%
  separate(Stock_Variable, into = c("species", "Variable"), sep = "_", extra = "merge")  # Split into two columns

# Extract year from Variable (assuming yyyy_Total Catch format)
colnames(stocks_long)[colnames(stocks_long) == "Stock Name_Assessment Year_Description"] <- "Year"

# Convert Year to numeric
stocks_total_catch <- stocks_long %>%
  mutate(Year = as.numeric(Year))

stocks_total_catch <- stocks_total_catch %>%
  mutate(Value = as.numeric(Value))

unique(stocks_long$Variable)  # See all unique variable names

# Keep only "Total Catch"
stocks_total_catch <- stocks_total_catch %>%
  dplyr::filter(str_detect(Variable, "Total Catch|Estimated Commercial Catch")) %>%
  dplyr::select(Year, species, Value)  # Keep only relevant columns

colnames(stocks_total_catch)[colnames(stocks_total_catch) == "Value"] <- "Total_Catch"

# Inspect cleaned dataset
head(stocks_total_catch, 10)
str(stocks_total_catch)
summary(stocks_total_catch)
```

### Monthly Mean Average Temperature
```{r}
## Portland
# Load Temperature Data Weather.gov
portland_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Portland_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(portland_temp)
head(portland_temp, 10)
str(portland_temp)
summary(portland_temp)

# Load Precipitation Data
Portland_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Portland_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(Portland_precip)
head(Portland_precip, 10)
str(Portland_precip)
summary(Portland_precip)

## Belfast
# Load Temperature Data Weather.gov
belfast_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Belfast_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(belfast_temp)
head(belfast_temp, 10)
str(belfast_temp)
summary(belfast_temp)

# Load Precipitation Data
belfast_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Belfast_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(belfast_precip)
head(belfast_precip, 10)
str(belfast_precip)
summary(belfast_precip)

## Moosehead
# Load Temperature Data Weather.gov
moosehead_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Moosehead_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(moosehead_temp)
head(moosehead_temp, 10)
str(moosehead_temp)
summary(moosehead_temp)

# Load Precipitation Data
moosehead_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Moosehead_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(moosehead_precip)
head(moosehead_precip, 10)
str(moosehead_precip)
summary(moosehead_precip)

## Gardiner
# Load Temperature Data Weather.gov
gardiner_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Gardiner_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(gardiner_temp)
head(gardiner_temp, 10)
str(gardiner_temp)
summary(gardiner_temp)

# Load Precipitation Data
gardiner_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Gardiner_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(gardiner_precip)
head(gardiner_precip, 10)
str(gardiner_precip)
summary(gardiner_precip)

## Augusta
# Load Temperature Data Weather.gov
augusta_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Augusta_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(augusta_temp)
head(augusta_temp, 10)
str(augusta_temp)
summary(augusta_temp)

# Load Precipitation Data
augusta_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Augusta_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(augusta_precip)
head(augusta_precip, 10)
str(augusta_precip)
summary(augusta_precip)

convert_to_numeric <- function(df) {
  df[] <- lapply(df, function(x) as.numeric(as.character(x)))  # Convert all columns to numeric
  return(df)
}

# Portland
portland_temp <- convert_to_numeric(portland_temp)
Portland_precip <- convert_to_numeric(Portland_precip)

# Belfast
belfast_temp <- convert_to_numeric(belfast_temp)
belfast_precip <- convert_to_numeric(belfast_precip)

# Moosehead
moosehead_temp <- convert_to_numeric(moosehead_temp)
moosehead_precip <- convert_to_numeric(moosehead_precip)

# Gardiner
gardiner_temp <- convert_to_numeric(gardiner_temp)
gardiner_precip <- convert_to_numeric(gardiner_precip)

# Augusta
augusta_temp <- convert_to_numeric(augusta_temp)
augusta_precip <- convert_to_numeric(augusta_precip)

```

### Maine Population Levels
```{r}
# Read in state-level population data
state_population <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/State_Population.csv",
                             stringsAsFactors = FALSE, check.names = TRUE)

# Convert wide format to long format
state_population_long <- state_population %>%
  pivot_longer(cols = starts_with("A00AA"), names_to = "Year", values_to = "Population") %>%
  mutate(Year = as.numeric(gsub("A00AA", "", Year))) %>%
  filter(Year >= 1950 & Year <= 2020)  # Keep only relevant years

# Interpolate missing years
state_population_interp <- state_population_long %>%
  complete(Year = full_seq(Year, 1)) %>%  # Fill missing years
  arrange(Year) %>%
  mutate(Population = zoo::na.approx(Population, na.rm = FALSE, rule = 2))  # Linear interpolation

# Read in county-level population data
county_population <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/County_Populations.csv",
                              stringsAsFactors = FALSE, check.names = TRUE)

# Convert wide format to long format
county_population_long <- county_population %>%
  pivot_longer(cols = starts_with("A00AA"), names_to = "Year", values_to = "Population") %>%
  mutate(Year = as.numeric(gsub("A00AA", "", Year))) %>%
  filter(Year >= 1950 & Year <= 2020)  # Keep only relevant years

# Interpolate missing years
county_population_interp <- county_population_long %>%
  complete(Year = full_seq(Year, 1), nesting(COUNTY)) %>%  # Fill missing years for each county
  arrange(COUNTY, Year) %>%
  group_by(COUNTY) %>%
  mutate(Population = zoo::na.approx(Population, na.rm = FALSE, rule = 2))  # Linear interpolation

# Save results
write.csv(state_population_interp, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/State_Population_Annual.csv", row.names = FALSE)
write.csv(county_population_interp, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/County_Population_Annual.csv", row.names = FALSE)

# Preview output
head(state_population_interp)
head(county_population_interp)

# Subset county-level population data
county_population_subset <- county_population_interp %>%
  dplyr::select(Year, COUNTY, Population)

# Subset state-level population data
state_population_subset <- state_population_interp %>%
  dplyr::select(Year, Population)

# Save the new subsets as CSV files
write.csv(county_population_subset, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/County_Population_Subset.csv", row.names = FALSE)
write.csv(state_population_subset, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/State_Population_Subset.csv", row.names = FALSE)

# Preview the subsets
head(county_population_subset)
head(state_population_subset)
```

### Historical GDP

```{r}
GDP <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Historical_GDP.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

head(GDP)

# Extract only the year from the Date column
gdp_data_cleaned <- GDP %>%
  dplyr:: mutate(Year = year(mdy(Date))) %>%  # Convert date and extract year
  dplyr::filter(Year >= 1950 & Year <= 2020) %>%  # Keep only years 1950-2020
  dplyr::select(Year, GDP..Billions.of.US..., Per.Capita..US..., Annual...Change)  # Keep relevant columns

# Save the cleaned dataset
write.csv(gdp_data_cleaned, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/GDP_Data_Cleaned.csv", row.names = FALSE)

# Preview the cleaned data
head(gdp_data_cleaned)
```

### Per Capita Consumption

```{r}
consumption <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Per_Captia_Consumption.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

head(consumption)
```

### Fisheries Exports

```{r}
# Load the data from CSV
exports <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Historical_Fisheries_Exports.csv",
                    stringsAsFactors = FALSE, 
                    check.names = FALSE, 
                    skip = 0)  # Skip no rows initially

# Transpose the data so that rows become columns
exports <- t(exports)

# Convert the transposed matrix to a data frame
exports_df <- as.data.frame(exports, stringsAsFactors = FALSE)

# Ensure that we are only converting the numeric data columns
exports_df[] <- lapply(exports_df, function(x) as.numeric(as.character(x)))

# Set the first row as the column names
colnames(exports_df) <- exports_df[1, ]

# Remove the first row (which is now redundant)
exports_df <- exports_df[-1, ]
rownames(exports_df) <- NULL

# Rename the columns to make the first one "Fishery_Exports" and the second one "Year"
colnames(exports_df)[1] <- "Fishery_Exports"
colnames(exports_df)[2] <- "Year"

# View the first few rows of the data frame to ensure everything is correct
head(exports_df)
```

### Fish Biomass for Northeast
```{r}
# Load the data from CSV
biomass <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/biomass-fish-stocks-region.csv",
                    stringsAsFactors = FALSE, 
                    check.names = FALSE, 
                    skip = 0)  # Skip no rows initially
```

### Fishing Pressure for Northeast
```{r}
# Load the data from CSV
fishing_pressure <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/fishing-pressure-by-region.csv",
                    stringsAsFactors = FALSE, 
                    check.names = FALSE, 
                    skip = 0)  # Skip no rows initially
```

### US Fish and Seafood Production
```{r}
# Load the data from CSV
production <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/fish-seafood-production.csv",
                    stringsAsFactors = FALSE, 
                    check.names = FALSE, 
                    skip = 0)  # Skip no rows initially
```

### Consumer Price Index

```{r}
CPI <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Consumer_Price_Index.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

head(CPI)

ggplot(CPI, aes(x = Year, y = Annual_CPI)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Linear trend
  labs(title = "Historical Consumer Price Index",
       y = "Mean Sea Level (m)", x = "Year") +
  theme_minimal()

```

### Consumer Price Index

```{r}
inflation <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Inflation_Rates.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

head(inflation)

ggplot(inflation, aes(x = Year, y = Annual_Inflation)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Linear trend
  labs(title = "Historical Consumer Price Index",
       y = "Mean Sea Level (m)", x = "Year") +
  theme_minimal()
```

## Preprocessing

### Sea- Level

```{r}
ggplot(water_levels, aes(x = Year, y = Mean_Sea_Level_m, color = Station)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Linear trend
  labs(title = "Historical Mean Sea Level Trends in Maine",
       y = "Mean Sea Level (m)", x = "Year") +
  theme_minimal()

```
```{r}
# Fit linear regression model for each station
linear_models <- water_levels %>%
  group_by(Station) %>%
  do(model = lm(Mean_Sea_Level_m ~ Year, data = .))

# Extract slope (sea level rise rate) for each station
slopes <- linear_models %>%
  summarise(Station, Rate_m_per_year = coef(model)[2])

print(slopes)

```


### Landings and Value

```{r}
# Aggregate total landings per year for each species
landings_yearly <- landings %>%
  group_by(year, species) %>%
  summarize(Total_Weight_kg = sum(total_weight, na.rm = TRUE),
            Total_Value = sum(total_value, na.rm = TRUE),
            Avg_Market_Price = mean(market_price_per_Kg)) %>%
  ungroup()  # Ensure no lingering groupings

# Inspect results
head(landings_yearly)

```

### Lobster Landings

```{r}
# Set the first row as row names
colnames(lobster_County) <- lobster_County[1, ]

# Remove the first row from the dataset
lobster_County <- lobster_County[-1, ]

# Reset row indices
rownames(lobster_County) <- NULL

# Inspect the cleaned dataset
head(lobster_County)

# Convert Year to integer
lobster_County$Year <- as.integer(lobster_County$Year)

# Convert Pounds and Value to numeric (removing any commas)
lobster_County <- lobster_County %>%
  mutate(
    Pounds = as.numeric(gsub(",", "", Pounds)), 
    Value = as.numeric(gsub(",", "", Value))
  )

# Now summarize by Year and County
lobster_summary <- lobster_County %>%
  group_by(Year, County) %>%
  summarize(
    Total_Pounds = sum(Pounds, na.rm = TRUE),
    Total_Value = sum(Value, na.rm = TRUE)
  )

# Inspect the results
head(lobster_summary)

colnames(landings_yearly)[colnames(landings_yearly) == "year"] <- "Year"
colnames(lobster_summary)[colnames(lobster_summary) == "Total_Pounds"] <- "Lobster_Pounds"
colnames(lobster_summary)[colnames(lobster_summary) == "Total_Value"] <- "Lobster_Value"

# Ensure Year is numeric in all datasets
landings_yearly$Year <- as.integer(landings_yearly$Year)
lobster_summary$Year <- as.integer(lobster_summary$Year)
water_levels$Year <- as.integer(water_levels$Year)

# Merge Landings Data with Lobster Data (preserving county information)
merged_data <- landings_yearly  %>%
  left_join(lobster_summary, by = "Year")

# Merge with sea level data (averaging across stations)
merged_data <- merged_data %>%
  left_join(water_levels %>%
              group_by(Year) %>%
              summarize(Mean_Sea_Level_m = mean(Mean_Sea_Level_m, na.rm = TRUE)),
            by = "Year")

# Preview the merged dataset
head(merged_data)

# Check for any missing values
summary(merged_data)

```

### ENSO Data

```{r}

# Ensure Year is an integer
enso_data$Year <- as.integer(enso_data$YR)

# Summarize by Year: Identify the dominant ENSO phase per year
dominant_enso <- enso_data %>%
  dplyr::group_by(Year, ENSO_Phase) %>%
  dplyr::summarise(Count = n(), .groups = "drop") %>%  # Count occurrences of each phase per year
  dplyr::arrange(Year, desc(Count)) %>%  # Sort by Year and Count (descending)
  dplyr::distinct(Year, .keep_all = TRUE) %>%  # Keep only the most frequent ENSO phase per year
  dplyr::select(Year, ENSO_Phase)  # Keep only relevant columns

# Merge dominant ENSO phase with merged_data
merged_data <- merged_data %>%
  left_join(dominant_enso, by = "Year")

# Inspect results
head(merged_data)
```

### Temperature and Precipitation Data

```{r}
## Portland
# Convert Year column
portland_temp$Year <- as.integer(portland_temp$Year)
Portland_precip$Year <- as.integer(Portland_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
portland_temp <- portland_temp %>%
  rename(Portland_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
Portland_precip <- Portland_precip %>%
  rename(Portland_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(portland_temp %>% dplyr::select(Year, Portland_Annual_Temp), by = "Year") %>%
  left_join(Portland_precip %>% dplyr::select(Year, Portland_Annual_Precip), by = "Year")

## Belfast
# Convert Year column
belfast_temp$Year <- as.integer(belfast_temp$Year)
belfast_precip$Year <- as.integer(belfast_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
belfast_temp <- belfast_temp %>%
  rename(Belfast_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
belfast_precip <- belfast_precip %>%
  rename(Belfast_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(belfast_temp %>% dplyr::select(Year, Belfast_Annual_Temp), by = "Year") %>%
  left_join(belfast_precip %>% dplyr::select(Year, Belfast_Annual_Precip), by = "Year")

## Moosehead
# Convert Year column
moosehead_temp$Year <- as.integer(moosehead_temp$Year)
moosehead_precip$Year <- as.integer(moosehead_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
moosehead_temp <- moosehead_temp %>%
  rename(Moosehead_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
moosehead_precip <- moosehead_precip %>%
  rename(Moosehead_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(moosehead_temp %>% dplyr::select(Year, Moosehead_Annual_Temp), by = "Year") %>%
  left_join(moosehead_precip %>% dplyr::select(Year, Moosehead_Annual_Precip), by = "Year")

## Gardnier
# Convert Year column
gardiner_temp$Year <- as.integer(gardiner_temp$Year)
gardiner_precip$Year <- as.integer(gardiner_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
gardiner_temp <- gardiner_temp %>%
  rename(Gardiner_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
gardiner_precip <- gardiner_precip %>%
  rename(Gardiner_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(gardiner_temp %>% dplyr::select(Year, Gardiner_Annual_Temp), by = "Year") %>%
  left_join(gardiner_precip %>% dplyr::select(Year, Gardiner_Annual_Precip), by = "Year")

## Augusta
# Convert Year column
augusta_temp$Year <- as.integer(augusta_temp$Year)
augusta_precip$Year <- as.integer(augusta_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
augusta_temp <- augusta_temp %>%
  rename(Augusta_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
augusta_precip <- augusta_precip %>%
  rename(Augusta_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(augusta_temp %>% dplyr::select(Year, Augusta_Annual_Temp), by = "Year") %>%
  left_join(augusta_precip %>% dplyr::select(Year, Augusta_Annual_Precip), by = "Year")

# Replace any "M" values with NA
merged_data[merged_data == "M"] <- NA

head(merged_data)
summary(merged_data)
```

### North Atlantic Oscillation Index
```{r}
# Compute annual mean NAO index
NAO_annual <- NAO_long %>%
  group_by(Year) %>%
  summarize(Annual_NAO = mean(NAO_Index, na.rm = TRUE))  # Average across months

# Merge NAO data with existing merged_data
merged_data <- merged_data %>%
  left_join(NAO_annual, by = "Year")  # Match based on Year column

# Check merged dataset
head(merged_data)
```

### Historic GDP

```{r}
# Merge GDP data with existing merged_data
merged_data <- merged_data %>%
  left_join(gdp_data_cleaned, by = "Year")  # Match based on Year column

```

### Per Capita Consumption

```{r}
# Merge GDP data with existing merged_data
merged_data <- merged_data %>%
  left_join(consumption, by = "Year")  # Match based on Year column
```

### Maine Population
```{r}
colnames(state_population_subset)[colnames(state_population_subset) == "Population"] <- "State_Population"

# Merge State Population data with existing merged_data
merged_data <- merged_data %>%
  left_join(state_population_subset, by = "Year")  # Match based on Year column

colnames(county_population_subset)[colnames(county_population_subset) == "COUNTY"] <- "County"
colnames(county_population_subset)[colnames(county_population_subset) == "Population"] <- "County_Population"

# Remove the word "County" from the County column
#county_population_subset$County <- gsub(" County", "", county_population_subset$County)

# Display the first few rows to verify the change
#head(county_population_subset)

# Merge GDP data with existing merged_data
#merged_data <- merged_data %>%
#  left_join(county_population_subset, by = c("Year", "County"))  # Match based on Year column
```

### Fisheries Exports

```{r}
# Merge Export data with existing merged_data

merged_data <- merged_data %>%
  left_join(exports_df, by = "Year")  # Match based on Year column

merged_data$Fishery_Exports <- ifelse(merged_data$Fishery_Exports == 0, NA, merged_data$Fishery_Exports)

```


### Fish Biomass for Northeast
```{r}
merged_data <- merged_data %>%
  left_join(biomass, by = "Year")  # Match based on Year column

```

### Fishing Pressure for Northeast
```{r}
merged_data <- merged_data %>%
  left_join(fishing_pressure, by = "Year")  # Match based on Year column

```

### US Fish and Seafood Production
```{r}
merged_data <- merged_data %>%
  left_join(production, by = "Year")  # Match based on Year column
colnames(merged_data)[colnames(merged_data) == "Fish Seafood Tonnes"] <- "Fish_Seafood_Production"

```

### Inflation
```{r}
merged_data <- merged_data %>%
  left_join(CPI, by = "Year")  # Match based on Year column
```

### CPI
```{r}
merged_data <- merged_data %>%
  left_join(inflation, by = "Year")  # Match based on Year column
```

### Interpolate Missing Values

```{r}
# Interpolate NA Values
head(merged_data,10)

# Function to interpolate numeric columns
interpolate_numeric <- function(x) {
  if (is.numeric(x)) {
    return(na.approx(x, rule = 2))  # Linear interpolation
  } else {
    return(x)  # Return as is if not numeric
  }
}

# Apply interpolation to numeric columns
interpolated_data <- merged_data %>%
  mutate(across(where(is.numeric), interpolate_numeric))

# Fill missing categorical values using last observation carried forward
interpolated_data <- interpolated_data %>%
  mutate(across(where(is.character), ~na.locf(.x, na.rm = FALSE)))

```

### Stock Assessment

```{r}

#species_list1 <- unique(interpolated_data$species)
#print(species_list1)
#species_list2 <- unique(stocks_total_catch$species)
#print(species_list2)

# Function to clean species names
#clean_species_name <- function(species) {
#  species <- str_trim(species)  # Remove extra spaces
#  species <- str_remove(species, "Gulf of Maine.*")  # Remove extra descriptors
#  species <- str_remove(species, "Georges Bank.*")   # Remove extra descriptors
#  species <- str_remove(species, "\\d+$")           # Remove trailing numbers
#  return(species)
#}

# Apply cleaning function
#species_list2_clean <- unique(sapply(species_list2, clean_species_name))

# Function to find closest match
#find_closest_match <- function(species, species_list) {
#  if (is.na(species) || species == "") return(NA)  # Handle missing values
#  
#  distances <- stringdist(species, species_list, method = "jw")  # Jaro-Winkler similarity
#  closest_index <- which.min(distances)  # Get closest match
#  return(species_list[closest_index])  # Return best match
#}

# Apply matching function
#matched_species <- vapply(species_list2_clean, find_closest_match, character(1), species_list = species_list1)

# Create a lookup table
#species_mapping <- data.frame(Original_Species = species_list2_clean, Matched_Species = matched_species)

# Inspect mapping
#print(species_mapping)

# Ensure stocks_long species names match cleaned species list
#stocks_total_catch$Cleaned_Species <- sapply(stocks_total_catch$species, clean_species_name)

# Merge with fuzzy-matched species names
#stocks_total_catch <- stocks_total_catch %>%
#  left_join(species_mapping, by = c("Cleaned_Species" = "Original_Species"))

# Replace with matched species name
#stocks_total_catch$species <- stocks_total_catch$Matched_Species

# Drop temporary columns
#stocks_total_catch <- stocks_total_catch %>% dplyr::select(-Cleaned_Species, -Matched_Species)

# Verify changes
#head(stocks_total_catch)

#interpolated_data <- interpolated_data %>%
#  left_join(stocks_total_catch, by = c("Year", "species"))

# Check for missing matches
#summary(interpolated_data)

```

## Forecast Results

```{r}
#install.packages("vars")
#install.packages("BVAR")

colnames(interpolated_data)

# Set forecast years (2025-2100)
future_years <- seq(2020, 2040, by = 1)

# Convert ENSO Phase to Numeric
interpolated_data$ENSO_Phase <- ifelse(interpolated_data$ENSO_Phase == "El Niño", 1,
                                       ifelse(interpolated_data$ENSO_Phase == "La Niña", -1, 0))

head(interpolated_data,20)

# Get unique species
species_list <- unique(interpolated_data$species)
print(species_list)

```


### Sea-Level Rise Scenarios
```{r}
# Predict baseline sea levels (historical trend)
slr_model <- lm(Mean_Sea_Level_m ~ Year, data = interpolated_data)
baseline_sea_levels <- predict(slr_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Sea Level Rise Adjustments
low_slr <- baseline_sea_levels + (0.11 * ((future_years - 2020) / (2040 - 2020))^2)  # SSP1-2.6 (~0.44m by 2100)
moderate_slr <- baseline_sea_levels + (0.15 * ((future_years - 2020) / (2040 - 2025))^2)  # SSP2-4.5 (~0.60m by 2100)
high_slr <- baseline_sea_levels + (0.25 * ((future_years - 2020) / (2040 - 2020))^2)  # SSP5-8.5 (~1.0m by 2100)

# Create DataFrame for SLR Scenarios
slr_data <- data.frame(
  Year = rep(future_years, times = 3),
  SLR = c(low_slr, moderate_slr, high_slr),
  Scenario = rep(c("Low SLR", "Moderate SLR", "High SLR"), each = length(future_years))
)

# Plot SLR Scenarios
ggplot(slr_data, aes(x = Year, y = SLR, color = Scenario)) +
  geom_line(size = 1) +
  labs(title = "Projected Sea Level Rise Scenarios (2020-2040)",
       x = "Year", y = "Sea Level Rise (m)") +
  theme_minimal()

```

### Warming Scenarios
```{r}
## Portland

# Generate warming scenarios (based on temperature trends)
portland_temp_model <- lm(Portland_Annual_Temp ~ Year, data = interpolated_data)
portland_baseline_temp <- predict(portland_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
portland_low_temp <- portland_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
portland_moderate_temp <- portland_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
portland_high_temp <- portland_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
portland_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(portland_low_temp, portland_moderate_temp, portland_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(portland_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Portland, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()

## Belfast

# Generate warming scenarios (based on temperature trends)
belfast_temp_model <- lm(Belfast_Annual_Temp ~ Year, data = interpolated_data)
belfast_baseline_temp <- predict(belfast_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
belfast_low_temp <- belfast_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
belfast_moderate_temp <- belfast_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2025)))  # SSP2-4.5 (~2.7°C increase by 2100)
belfast_high_temp <- belfast_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
belfast_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(belfast_low_temp, belfast_moderate_temp, belfast_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(belfast_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Belfast, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()

## Moosehead

# Generate warming scenarios (based on temperature trends)
moosehead_temp_model <- lm(Moosehead_Annual_Temp ~ Year, data = interpolated_data)
moosehead_baseline_temp <- predict(moosehead_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
moosehead_low_temp <- moosehead_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
moosehead_moderate_temp <- moosehead_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
moosehead_high_temp <- moosehead_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
moosehead_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(moosehead_low_temp, moosehead_moderate_temp, moosehead_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(moosehead_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Moosehead, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()

## Gardiner

# Generate warming scenarios (based on temperature trends)
gardiner_temp_model <- lm(Gardiner_Annual_Temp ~ Year, data = interpolated_data)
gardiner_baseline_temp <- predict(gardiner_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
gardiner_low_temp <- gardiner_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
gardiner_moderate_temp <- gardiner_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
gardiner_high_temp <- gardiner_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
gardiner_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(gardiner_low_temp, gardiner_moderate_temp, gardiner_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(gardiner_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Gardiner, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()

## Augusta

# Generate warming scenarios (based on temperature trends)
augusta_temp_model <- lm(Augusta_Annual_Temp ~ Year, data = interpolated_data)
augusta_baseline_temp <- predict(augusta_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
augusta_low_temp <- augusta_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
augusta_moderate_temp <- augusta_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
augusta_high_temp <- augusta_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
augusta_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(augusta_low_temp, augusta_moderate_temp, augusta_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(augusta_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Augusta, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()
```

### ENSO Scenarios
```{r}
set.seed(42)  # Ensure reproducibility

# Use future_years (2020-2100)
enso_2yr_future <- sin(2 * pi * (future_years - min(future_years)) / 2)  # 2-year cycle
enso_3yr_future <- sin(2 * pi * (future_years - min(future_years)) / 3)  # 3-year cycle
enso_5yr_future <- sin(2 * pi * (future_years - min(future_years)) / 5)  # 5-year cycle
enso_7yr_future <- sin(2 * pi * (future_years - min(future_years)) / 7)  # 7-year cycle

# Combine into a dataframe
enso_scenarios <- data.frame(
  Year = future_years,
  ENSO_2yr = enso_2yr_future,
  ENSO_3yr = enso_3yr_future,
  ENSO_5yr = enso_5yr_future,
  ENSO_7yr = enso_7yr_future
)

# Visualize ENSO cycles for the future period (2020-2100)
enso_scenarios %>%
  pivot_longer(cols = starts_with("ENSO"), names_to = "Cycle", values_to = "Index") %>%
  ggplot(aes(x = Year, y = Index, color = Cycle)) +
  geom_line(linewidth = 1) +
  theme_minimal() +
  labs(title = "Simulated ENSO Cycles (2020-2100)", y = "ENSO Index", x = "Year")

```

### Population Trends
```{r}
# Generate a simple trend model for state_population
state_population_model <- lm(State_Population ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_state_population <- predict(state_population_model, newdata = data.frame(Year = future_years))

## By country
# Generate a simple trend model for state_population
civilian_population_model <- lm(Civilian.Population..Millions. ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_Civilian.Population..Millions. <- predict(civilian_population_model, newdata = data.frame(Year = future_years))
```

### Economic Trends
```{r}
# Generate a simple trend model for state_population
inflation_model <- lm(Annual_Inflation ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_inflation <- predict(inflation_model, newdata = data.frame(Year = future_years))

# Generate a simple trend model for state_population
capita_model <- lm(Per.Capita..US... ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_capita <- predict(capita_model, newdata = data.frame(Year = future_years))

# Generate a simple trend model for state_population
annual_change_model <- lm(Annual...Change ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_annual_change <- predict(annual_change_model, newdata = data.frame(Year = future_years))
```

### Fishing

```{r}
# Generate a simple trend model for state_population
fishing_pressure_model <- lm(fishing_pressure_mean_region ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_fishing_pressure <- predict(fishing_pressure_model, newdata = data.frame(Year = future_years))

# Generate a simple trend model for state_population
annual_Fish_Seafood_Production_model <- lm(Fish_Seafood_Production ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_Fish_Seafood_Production <- predict(annual_Fish_Seafood_Production_model, newdata = data.frame(Year = future_years))
```

### All Scenarios
```{r}
colnames(interpolated_data)
# Create scenario-specific datasets with NAO included
future_scenarios <- list(
  # Baseline Scenario
# Baseline Scenario
"Baseline" = data.frame(
  Year = future_years, 
  Mean_Sea_Level_m = baseline_sea_levels,  # Historical trend for sea level
  Portland_Annual_Temp = portland_baseline_temp,  # Baseline temperature for Portland
  Belfast_Annual_Temp = belfast_baseline_temp,  # Baseline temperature for Belfast
  Moosehead_Annual_Temp = moosehead_baseline_temp,  # Baseline temperature for Moosehead
  Gardiner_Annual_Temp = gardiner_baseline_temp,  # Baseline temperature for Gardiner
  Augusta_Annual_Temp = augusta_baseline_temp,  # Baseline temperature for Augusta
  Civilian.Population..Millions. = future_Civilian.Population..Millions.,  
  State_Population = future_state_population,
  Annual_Inflation = future_inflation
#  GDP..Billions.of.US... = future_GDP,
#  Per.Capita..US... = future_capita, 
#  Annual...Change = future_annual_change,
#  fishing_pressure_mean_region = future_fishing_pressure,
#  Fish_Seafood_Production = future_Fish_Seafood_Production
),

# Low Climate Change (SLR Low, Temp Low)
"Low_Climate" = data.frame(
  Year = future_years, 
  Mean_Sea_Level_m = low_slr,  # Low sea-level rise projection
  Portland_Annual_Temp = portland_low_temp,  # Low warming projection for Portland
  Belfast_Annual_Temp = belfast_low_temp,  # Low warming projection for Belfast
  Moosehead_Annual_Temp = moosehead_low_temp,  # Low warming projection for Moosehead
  Gardiner_Annual_Temp = gardiner_low_temp,  # Low warming projection for Gardiner
  Augusta_Annual_Temp = augusta_low_temp,  # Low warming projection for Augusta
  Civilian.Population..Millions. = future_Civilian.Population..Millions.,  
  State_Population = future_state_population,
  Annual_Inflation = future_inflation#  GDP..Billions.of.US... = future_GDP,
#  Per.Capita..US... = future_capita, 
#  Annual...Change = future_annual_change,
#  fishing_pressure_mean_region = future_fishing_pressure,
#  Fish_Seafood_Production = future_Fish_Seafood_Production
  ),

# Moderate Climate Change (SLR Moderate, Temp Moderate)
"Moderate_Climate" = data.frame(
  Year = future_years, 
  Mean_Sea_Level_m = moderate_slr,  # Moderate sea-level rise projection
  Portland_Annual_Temp = portland_moderate_temp,  # Moderate warming projection for Portland
  Belfast_Annual_Temp = belfast_moderate_temp,  # Moderate warming projection for Belfast
  Moosehead_Annual_Temp = moosehead_moderate_temp,  # Moderate warming projection for Moosehead
  Gardiner_Annual_Temp = gardiner_moderate_temp,  # Moderate warming projection for Gardiner
  Augusta_Annual_Temp = augusta_moderate_temp,  # Moderate warming projection for Augusta
  Civilian.Population..Millions. = future_Civilian.Population..Millions.,  
  State_Population = future_state_population,
  Annual_Inflation = future_inflation
#  GDP..Billions.of.US... = future_GDP,
#  Per.Capita..US... = future_capita, 
#  Annual...Change = future_annual_change,
#  fishing_pressure_mean_region = future_fishing_pressure,
#  Fish_Seafood_Production = future_Fish_Seafood_Production
),

# Extreme Climate Change (SLR High, Temp High)
"Extreme_Climate" = data.frame(
  Year = future_years, 
  Mean_Sea_Level_m = high_slr,  # High sea-level rise projection
  Portland_Annual_Temp = portland_high_temp,  # Extreme warming projection for Portland
  Belfast_Annual_Temp = belfast_high_temp,  # Extreme warming projection for Belfast
  Moosehead_Annual_Temp = moosehead_high_temp,  # Extreme warming projection for Moosehead
  Gardiner_Annual_Temp = gardiner_high_temp,  # Extreme warming projection for Gardiner
  Augusta_Annual_Temp = augusta_high_temp,  # Extreme warming projection for Augusta
  Civilian.Population..Millions. = future_Civilian.Population..Millions.,  
  State_Population = future_state_population,
  Annual_Inflation = future_inflation
#  GDP..Billions.of.US... = future_GDP,
#  Per.Capita..US... = future_capita, 
#  Annual...Change = future_annual_change,
#  fishing_pressure_mean_region = future_fishing_pressure,
#  Fish_Seafood_Production = future_Fish_Seafood_Production
)
  
)

# Extract all required variables from the training dataset
required_vars <- colnames(interpolated_data)

# Function to add missing variables with the last observed value
fill_missing_with_last_value <- function(df_train, df_future) {
  for (var in required_vars) {
    if (!(var %in% colnames(df_future))) {
      # Get last observed (non-NA) value from df_train
      last_value <- tail(df_train[[var]][!is.na(df_train[[var]])], 1)
      
      # If there is no historical value (completely missing column), set to NA
      if (length(last_value) == 0) {
        last_value <- NA
      }
      
      # Assign the last observed value to all future years
      df_future[[var]] <- last_value
    }
  }
  return(df_future)
}

# Apply the function to all future scenarios
future_scenarios <- lapply(future_scenarios, function(df) {
  fill_missing_with_last_value(interpolated_data, df)
})
```

### Predict Species Results

```{r}
# Predict Landings (Total_weight) using environmental parameters and Maine Population
# sea level rise
# portland precipitation
# portland temperature
# NAO Index
# State Population

#predict US Consumption using civillian population and landings

# predict US exports from Maine using consumption, landings

# predict market value using GDP, Annual Change, Per capita, total_weight, consumption, and exports

# Predict total value or Maine Blue Economy using market value and total_weight
# Define base output directory
base_output_dir <- "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/Plots"

# Ensure base output directory exists
if (!dir.exists(base_output_dir)) {
  dir.create(base_output_dir, recursive = TRUE)
  cat("Created base directory:", base_output_dir, "\n")
}

# Load dataset
df <- interpolated_data

# Function to sanitize species names for file/folder use
sanitize_name <- function(name) {
  name %>%
    str_replace_all("[^A-Za-z0-9]", "_") %>%  # Replace special characters with underscores
    str_trim()  # Trim extra spaces
}

# Get sanitized species list
species_list <- unique(df$species)

# Initialize lists to store results
all_species_results <- list()
zero_landings_species <- list()

# Iterate through each species
for (species_name in species_list) {
  
  cat("Processing:", species_name, "\n")

  # Create a sanitized directory name
  species_folder_name <- sanitize_name(species_name)
  species_output_dir <- file.path(base_output_dir, species_folder_name)
  
  if (!dir.exists(species_output_dir)) {
    dir.create(species_output_dir, recursive = TRUE)
  }

  # Filter data for the current species
  df_species <- df %>% filter(species == species_name)

  # Ensure enough data points exist for training
  if (nrow(df_species) < 10) {
    cat("Skipping", species_name, "- Not enough data\n")
    next
  }

  # 🔹 Train Landings Model
  landings_data <- df_species %>%
    dplyr::select(Total_Weight_kg, fishing_pressure_mean_region, State_Population, Mean_Sea_Level_m, Portland_Annual_Precip, Portland_Annual_Temp, Belfast_Annual_Precip, Belfast_Annual_Temp, 
                  Gardiner_Annual_Precip, Gardiner_Annual_Temp, Augusta_Annual_Precip,
                  Augusta_Annual_Temp, Annual_NAO)

  set.seed(123)
  trainIndex <- createDataPartition(landings_data$Total_Weight_kg, p = 0.7, list = FALSE)
  train_landings <- landings_data[trainIndex, ]
  test_landings <- landings_data[-trainIndex, ]

  rf_landings <- randomForest(Total_Weight_kg ~ ., data = train_landings, ntree = 2000)
  
  # 🔹 Train Consumption Model
  consumption_data <- df_species %>%
    dplyr::select(Total..Pounds., Total_Weight_kg, Civilian.Population..Millions., State_Population, Fish_Seafood_Production)
  
  trainIndex <- createDataPartition(consumption_data$Total..Pounds., p = 0.7, list = FALSE)
  train_consumption <- consumption_data[trainIndex, ]
  test_consumption <- consumption_data[-trainIndex, ]
  
  rf_consumption <- randomForest(Total..Pounds. ~ ., data = consumption_data, ntree = 2000)
  
  # 🔹 Train Exports Model
  exports_data <- df_species %>%
    dplyr::select(Fishery_Exports, Total_Weight_kg, Total..Pounds.,  Civilian.Population..Millions., Fish_Seafood_Production)

  rf_exports <- randomForest(Fishery_Exports ~ ., data = exports_data, ntree = 2000)

  trainIndex <- createDataPartition(exports_data$Fishery_Exports, p = 0.7, list = FALSE)
  train_exports <- exports_data[trainIndex, ]
  test_exports <- exports_data[-trainIndex, ]
  
  # 🔹 Train Market Value Model
  market_value_data <- df_species %>%
    dplyr::select(Avg_Market_Price, GDP..Billions.of.US..., Annual...Change, 
                  Per.Capita..US..., Total_Weight_kg, Total..Pounds., Civilian.Population..Millions., Annual_Inflation)
  
  trainIndex <- createDataPartition(market_value_data$Avg_Market_Price, p = 0.7, list = FALSE)
  train_market_value <- market_value_data[trainIndex, ]
  test_market_value <- market_value_data[-trainIndex, ]
  
  rf_market_value <- randomForest(Avg_Market_Price ~ ., data = market_value_data, ntree = 2000)

  # 🔹 Train Blue Economy Model
  blue_economy_data <- df_species %>%
    dplyr::select(Total_Value, Avg_Market_Price, Total_Weight_kg, Total..Pounds., Fishery_Exports, Mean_Sea_Level_m)
  
  trainIndex <- createDataPartition(blue_economy_data$Total_Value, p = 0.7, list = FALSE)
  train_blue_economy <- blue_economy_data[trainIndex, ]
  test_blue_economy <- blue_economy_data[-trainIndex, ]
  
  rf_blue_economy <- randomForest(Total_Value ~ ., data = blue_economy_data, ntree = 2000)

  # Evaluate Models
  
  # Define function for model evaluation
  evaluate_model <- function(model, train_data, test_data, target_var, model_name) {
  
  # Predictions
  pred_train <- predict(model, newdata = train_data)
  pred_test <- predict(model, newdata = test_data)
  
  # Compute RMSE
  rmse_train <- RMSE(pred_train, train_data[[target_var]])
  rmse_test <- RMSE(pred_test, test_data[[target_var]])
  
  # Compute R²
  r2_test <- postResample(pred_test, test_data[[target_var]])[2]
  r2_train <- postResample(pred_train, train_data[[target_var]])[2]
  
  # Save results to CSV
    evaluation_results <- data.frame(
      Model = model_name,
      RMSE_Train = rmse_train,
      RMSE_Test = rmse_test,
      R2_Train = r2_train,
      R2_Test = r2_test
    )
    
    eval_csv_file <- file.path(species_output_dir, "Model_Evaluation.csv")
    
    if (!file.exists(eval_csv_file)) {
      write.csv(evaluation_results, eval_csv_file, row.names = FALSE)
    } else {
      write.table(evaluation_results, eval_csv_file, sep = ",", col.names = !file.exists(eval_csv_file), append = TRUE, row.names = FALSE)
    }
    # Print Results
  cat(model_name, "- RMSE (Train):", rmse_train, " | RMSE (Test):", rmse_test, "\n")
  cat(model_name, "- R² (Train):", r2_train, " | R² (Test):", r2_test, "\n")
  
  # Feature Importance
  importance_values <- importance(model)
  print(paste(model_name, "Feature Importance:"))
  print(importance_values)
  
  # Cross-Validation
  cv_control <- trainControl(method = "cv", number = 5)
  cv_model <- train(as.formula(paste(target_var, "~ .")), data = train_data, method = "rf", trControl = cv_control)
  print(paste(model_name, "Cross-Validation Results:"))
  print(cv_model)
  
  # Hyperparameter Tuning
  cat("Tuning hyperparameters for", model_name, "...\n")
  tuneRF(train_data[, -which(names(train_data) == target_var)], train_data[[target_var]], stepFactor = 1.5, improve = 0.01)
  
  # Save Performance Plot
  plot_data <- data.frame(
    Actual = test_data[[target_var]],
    Predicted = pred_test
  )
  
  plot_file <- file.path(species_output_dir, paste0(model_name, "_Performance.png"))
  
  p <- ggplot(plot_data, aes(x = Actual, y = Predicted)) +
    geom_point() +
    geom_abline(color = "red", linetype = "dashed") +
    ggtitle(paste(model_name, "Predicted vs Actual")) +
    xlab("Actual Values") + ylab("Predicted Values") +
    theme_minimal()
  
  ggsave(plot_file, plot = p, width = 8, height = 5)
  cat("Saved performance plot for", model_name, ":", plot_file, "\n")
}
  # 🔹 **Evaluate Each Model**
  evaluate_model(rf_landings, train_landings, test_landings, "Total_Weight_kg", "Landings Model")
  evaluate_model(rf_consumption, train_consumption, test_consumption, "Total..Pounds.", "Consumption Model")
  evaluate_model(rf_exports, train_exports, test_exports, "Fishery_Exports", "Exports Model")
  evaluate_model(rf_market_value, train_market_value, test_market_value, "Avg_Market_Price", "Market Value Model")
  evaluate_model(rf_blue_economy, train_blue_economy, test_blue_economy, "Total_Value", "Blue Economy Model")

  # 🔹 Iterate Through Climate & Population Scenarios
  scenario_results <- list()

  for (scenario_name in names(future_scenarios)) {
    
    future_df <- future_scenarios[[scenario_name]]
    
    # Predict Future Landings
    future_df$Predicted_Landings <- predict(rf_landings, newdata = future_df)
    future_df$Total_Weight_kg <- future_df$Predicted_Landings  
    
    # Predict Future Consumption
    future_df$Predicted_Consumption <- predict(rf_consumption, newdata = future_df)

    # Predict Future Exports
    future_df$Predicted_Exports <- predict(rf_exports, newdata = future_df)

    # Predict Future Market Value
    future_df$Predicted_Market_Value <- predict(rf_market_value, newdata = future_df)

    # Predict Future Blue Economy Value
    future_df$Predicted_Blue_Economy_Value <- predict(rf_blue_economy, newdata = future_df)

    # Store results
    scenario_results[[scenario_name]] <- future_df
  }

  # Combine results into a single dataframe
  results_df <- bind_rows(scenario_results, .id = "Scenario")

  # Save species-level results
  csv_file <- file.path(species_output_dir, "Forecasts.csv")
  write.csv(results_df, csv_file, row.names = FALSE)
  cat("Saved species forecast:", csv_file, "\n")

  # Store in master results list
  results_df$Species <- species_name
  all_species_results[[species_name]] <- results_df

  # Identify species where landings reach 0 or negative
  if (any(results_df$Total_Weight_kg <= 0, na.rm = TRUE)) {
    zero_landings_species[[species_name]] <- results_df %>% filter(Total_Weight_kg <= 0)
  }

   # 🔹 Plot Market Value, Landings, and Blue Economy Value with a Line for Each Scenario
  market_value_plot <- ggplot(results_df, aes(x = Year, y = Predicted_Market_Value, color = Scenario)) +
    geom_line(size = 1.2) +
    ggtitle(paste("Market Value Projection for", species_name)) +
    xlab("Year") + ylab("Market Value ($/kg)") +
    xlim(2025, 2040) +  # Limit x-axis range
    theme_minimal()

  ggsave(file.path(species_output_dir, "Market_Value.png"), plot = market_value_plot, width = 8, height = 5)

  landings_plot <- ggplot(results_df, aes(x = Year, y = Total_Weight_kg, color = Scenario)) +
    geom_line(size = 1.2) +
    ggtitle(paste("Landings Projection for", species_name)) +
    xlab("Year") + ylab("Total Weight (kg)") +
    xlim(2025, 2040) +  # Limit x-axis range
    theme_minimal()

  ggsave(file.path(species_output_dir, "Landings.png"), plot = landings_plot, width = 8, height = 5)

  blue_economy_plot <- ggplot(results_df, aes(x = Year, y = Predicted_Blue_Economy_Value, color = Scenario)) +
    geom_line(size = 1.2) +
    ggtitle(paste("Blue Economy Projection for", species_name)) +
    xlab("Year") + ylab("Total Economic Value ($)") +
    xlim(2025, 2040) +  # Limit x-axis range
    theme_minimal()

  ggsave(file.path(species_output_dir, "Blue_Economy.png"), plot = blue_economy_plot, width = 8, height = 5)
}

# 🔹 Save All Species Forecasts to One Master File
master_results_df <- bind_rows(all_species_results)
master_csv_file <- file.path(base_output_dir, "All_Species_Forecasts.csv")
write.csv(master_results_df, master_csv_file, row.names = FALSE)
cat("Saved master forecast file:", master_csv_file, "\n")

# 🔹 Save Species with Zero or Negative Landings
if (length(zero_landings_species) > 0) {
  zero_landings_df <- bind_rows(zero_landings_species, .id = "Species")
  zero_landings_file <- file.path(base_output_dir, "Species_Zero_Landings.csv")
  write.csv(zero_landings_df, zero_landings_file, row.names = FALSE)
  cat("Saved species with zero/negative landings:", zero_landings_file, "\n")
} else {
  cat("No species found with zero or negative landings.\n")
}
  
```


```{r}
# Define base directory
base_output_dir <- "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/Plots"

# Initialize lists to store aggregated results
all_results <- list()
zero_landings_species <- list()

# Iterate through species directories
species_dirs <- list.dirs(base_output_dir, recursive = FALSE)
print(species_dirs)
for (species_dir in species_dirs) {
  
  # Identify CSV file
  csv_file <- list.files(species_dir, pattern = "Forecasts.csv$", full.names = TRUE)
  
  if (length(csv_file) == 0) {
    next  # Skip if no CSV file exists
  }
  
  # Read the forecasted data
  species_results <- read.csv(csv_file)
  
  # Extract species name from directory
  species_name <- basename(species_dir)
  
  # Identify species where landings reach 0 or negative in any scenario
  if (any(species_results$Total_Weight_kg <= 0, na.rm = TRUE)) {
    zero_landings_species[[species_name]] <- species_results %>%
      filter(Total_Weight_kg <= 0)  # Store only problematic records
  }
  
  # Store results for aggregation
  all_results[[species_name]] <- species_results
}

# Combine all species' results into a single dataframe
combined_results <- bind_rows(all_results, .id = "Species")

# 🔹 **Aggregate Total Landings Across All Species Per Year Per Scenario**
total_landings_by_scenario <- combined_results %>%
  group_by(Year, Scenario) %>%
  summarise(
    Total_Aggregated_Landings = sum(Total_Weight_kg, na.rm = TRUE)
  ) %>%
  ungroup()

# Save total landings per scenario
total_landings_csv <- file.path(base_output_dir, "Maine_Total_Aggregated_Landings_By_Scenario.csv")
write.csv(total_landings_by_scenario, total_landings_csv, row.names = FALSE)
cat("Saved total aggregated landings per scenario:", total_landings_csv, "\n")

# 🔹 Aggregate **Total_Weight_kg** by **Scenario and Species**
maine_landings_by_species_scenario <- combined_results %>%
  group_by(Scenario, Species) %>%
  summarise(
    Total_Landings_kg = sum(Total_Weight_kg, na.rm = TRUE)
  ) %>%
  arrange(Scenario, desc(Total_Landings_kg))

# Save species-based landings data
maine_landings_by_species_csv <- file.path(base_output_dir, "Maine_Total_Landings_By_Species_By_Scenario.csv")
write.csv(maine_landings_by_species_scenario, maine_landings_by_species_csv, row.names = FALSE)
cat("Saved total landings by species per scenario:", maine_landings_by_species_csv, "\n")

# 🔹 Identify **Top 5 and Bottom 5 Species for Landings per Scenario**
top_5_species_scenario <- maine_landings_by_species_scenario %>%
  group_by(Scenario) %>%
  top_n(5, Total_Landings_kg) %>%
  arrange(Scenario, desc(Total_Landings_kg))

bottom_5_species_scenario <- maine_landings_by_species_scenario %>%
  group_by(Scenario) %>%
  top_n(-5, Total_Landings_kg) %>%
  arrange(Scenario, Total_Landings_kg)

# Save ranked lists
top_species_csv <- file.path(base_output_dir, "Top_5_Species_Landings_By_Scenario.csv")
write.csv(top_5_species_scenario, top_species_csv, row.names = FALSE)
cat("Saved top 5 species by landings per scenario:", top_species_csv, "\n")

bottom_species_csv <- file.path(base_output_dir, "Bottom_5_Species_Landings_By_Scenario.csv")
write.csv(bottom_5_species_scenario, bottom_species_csv, row.names = FALSE)
cat("Saved bottom 5 species by landings per scenario:", bottom_species_csv, "\n")

# 🔹 Compute Maine’s Net Blue Economy Value **for Each Scenario**
maine_blue_economy_by_scenario <- combined_results %>%
  group_by(Year, Scenario) %>%
  summarise(
    Net_Blue_Economy_Value = sum(Predicted_Blue_Economy_Value, na.rm = TRUE)
  ) %>%
  ungroup()

# Save scenario-specific Maine's Net Blue Economy Value
maine_blue_economy_csv <- file.path(base_output_dir, "Maine_Net_Blue_Economy_By_Scenario.csv")
write.csv(maine_blue_economy_by_scenario, maine_blue_economy_csv, row.names = FALSE)
cat("Saved Maine's Net Blue Economy Potential per scenario:", maine_blue_economy_csv, "\n")

# 🔹 Aggregate US Exports and Consumption per Scenario
aggregated_results_by_scenario <- combined_results %>%
  group_by(Year, Scenario) %>%
  summarise(
    Mean_Exports = mean(Predicted_Exports, na.rm = TRUE),
    Mean_Consumption = mean(Predicted_Consumption, na.rm = TRUE)) %>%
  ungroup()

# Save scenario-specific aggregated results
aggregated_csv_file <- file.path(base_output_dir, "Aggregated_Exports_Consumption_By_Scenario.csv")
write.csv(aggregated_results_by_scenario, aggregated_csv_file, row.names = FALSE)
cat("Saved aggregated exports & consumption by scenario:", aggregated_csv_file, "\n")

# Save species with zero/negative landings
zero_landings_file <- file.path(base_output_dir, "Species_Zero_Landings.csv")

if (length(zero_landings_species) > 0) {
  zero_landings_df <- bind_rows(zero_landings_species, .id = "Species")
  write.csv(zero_landings_df, zero_landings_file, row.names = FALSE)
  cat("Saved species with zero/negative landings:", zero_landings_file, "\n")
} else {
  cat("No species found with zero or negative landings.\n")
}

# 🔹 **Plot Total Landings Across All Species per Scenario**
total_landings_plot <- ggplot(total_landings_by_scenario, aes(x = Year, y = Total_Aggregated_Landings, color = Scenario)) +
  geom_line(size = 1.2) +
  ggtitle("Total Landings Across All Species by Scenario") +
  xlab("Year") + ylab("Total Landings (kg)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal()

total_landings_plot_file <- file.path(base_output_dir, "Total_Landings_Aggregated_By_Scenario.png")
ggsave(total_landings_plot_file, plot = total_landings_plot, width = 10, height = 6)
cat("Saved total landings plot by scenario:", total_landings_plot_file, "\n")

# 🔹 Extract Trends for the Selected Species
top_5_trends_scenario <- combined_results %>%
  filter(Species %in% top_5_species_scenario$Species)

bottom_5_trends_scenario <- combined_results %>%
  filter(Species %in% bottom_5_species_scenario$Species)

# 🔹 Plot **Top 5 Species Landings by Scenario**
top_5_plot <- ggplot(top_5_trends_scenario, aes(x = Year, y = Total_Weight_kg, color = Species)) +
  geom_line(size = 1.2) +
  facet_wrap(~Scenario, scales = "free") +
  ggtitle("Top 5 Species Landings by Scenario") +
  xlab("Year") + ylab("Total Landings (kg)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal()

top_5_plot_file <- file.path(base_output_dir, "Top_5_Species_Landings_By_Scenario.png")
ggsave(top_5_plot_file, plot = top_5_plot, width = 10, height = 6)
cat("Saved top 5 species landings plot by scenario:", top_5_plot_file, "\n")

# 🔹 Plot **Bottom 5 Species Landings by Scenario**
bottom_5_plot <- ggplot(bottom_5_trends_scenario, aes(x = Year, y = Total_Weight_kg, color = Species)) +
  geom_line(size = 1.2) +
  facet_wrap(~Scenario, scales = "free") +
  ggtitle("Bottom 5 Species Landings by Scenario") +
  xlab("Year") + ylab("Total Landings (kg)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal()

bottom_5_plot_file <- file.path(base_output_dir, "Bottom_5_Species_Landings_By_Scenario.png")
ggsave(bottom_5_plot_file, plot = bottom_5_plot, width = 10, height = 6)
cat("Saved bottom 5 species landings plot by scenario:", bottom_5_plot_file, "\n")

# 🔹 Plot Maine's Net Blue Economy Value for **Each Scenario**
maine_blue_economy_plot <- ggplot(maine_blue_economy_by_scenario, aes(x = Year, y = Net_Blue_Economy_Value, color = Scenario)) +
  geom_line(size = 1.2) +
  ggtitle("Projected Net Blue Economy Potential for Maine by Scenario") +
  xlab("Year") + ylab("Total Value ($)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal()

maine_blue_economy_plot_file <- file.path(base_output_dir, "Maine_Net_Blue_Economy_By_Scenario.png")
ggsave(maine_blue_economy_plot_file, plot = maine_blue_economy_plot, width = 8, height = 5)
cat("Saved Maine Net Blue Economy plot by scenario:", maine_blue_economy_plot_file, "\n")

# 🔹 US Exports Projection by Scenario
export_plot <- ggplot(aggregated_results_by_scenario, aes(x = Year, y = Mean_Exports, color = Scenario)) +
  geom_line(size = 1.2) +
  ggtitle("Projected US Fishery Exports by Scenario") +
  xlab("Year") + ylab("Mean Exports ($)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal()

export_plot_file <- file.path(base_output_dir, "Aggregated_Exports_By_Scenario.png")
ggsave(export_plot_file, plot = export_plot, width = 8, height = 5)
cat("Saved export projection plot by scenario:", export_plot_file, "\n")

# 🔹 US Consumption Projection by Scenario
consumption_plot <- ggplot(aggregated_results_by_scenario, aes(x = Year, y = Mean_Consumption, color = Scenario)) +
  geom_line(size = 1.2) +
  ggtitle("Projected US Fishery Consumption by Scenario") +
  xlab("Year") + ylab("Mean Consumption (Pounds)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal()

consumption_plot_file <- file.path(base_output_dir, "Aggregated_Consumption_By_Scenario.png")
ggsave(consumption_plot_file, plot = consumption_plot, width = 8, height = 5)
cat("Saved consumption projection plot by scenario:", consumption_plot_file, "\n")
```

### Which Species is Contributing the Most or the Least?

```{r}
# Initialize list to store results
all_species_results <- list()

# Iterate through species directories
species_dirs <- list.dirs(base_output_dir, recursive = FALSE)

for (species_dir in species_dirs) {
  
  # Identify CSV file
  csv_file <- list.files(species_dir, pattern = "Forecasts.csv$", full.names = TRUE)
  
  if (length(csv_file) == 0) {
    next  # Skip if no CSV file exists
  }
  
  # Read the forecasted data
  species_results <- read.csv(csv_file)
  
  # Extract species name from directory
  species_name <- basename(species_dir)
  
  # Add species name column
  species_results$Species <- species_name
  
  # Store results for aggregation
  all_species_results[[species_name]] <- species_results
}

# Combine all species' results into a single dataframe
combined_results <- bind_rows(all_species_results)

# 🔹 Compute **Total Economic Contribution Per Species Per Year for Each Scenario**
species_total_value_by_year_scenario <- combined_results %>%
  group_by(Year, Scenario, Species) %>%
  summarise(Annual_Economic_Contribution = sum(Predicted_Blue_Economy_Value, na.rm = TRUE)) %>%
  arrange(Year, Scenario, desc(Annual_Economic_Contribution))

# Compute **Percent Change in Economic Contribution Over Time**
species_total_value_by_year_scenario <- species_total_value_by_year_scenario %>%
  group_by(Scenario, Species) %>%
  arrange(Year) %>%
  mutate(Percent_Change = (Annual_Economic_Contribution - lag(Annual_Economic_Contribution)) / lag(Annual_Economic_Contribution) * 100)

# Save the **yearly species contribution ranking per scenario**
species_contribution_yearly_csv <- file.path(base_output_dir, "Species_Economic_Contribution_By_Year_By_Scenario.csv")
write.csv(species_total_value_by_year_scenario, species_contribution_yearly_csv, row.names = FALSE)
cat("Saved species economic contribution per year by scenario:", species_contribution_yearly_csv, "\n")

# 🔹 Identify **Top 5 and Bottom 5 Species for Each Scenario**
species_total_contribution_scenario <- species_total_value_by_year_scenario %>%
  group_by(Species, Scenario) %>%
  summarise(Total_Contribution = sum(Annual_Economic_Contribution, na.rm = TRUE)) %>%
  arrange(Scenario, desc(Total_Contribution))

top_5_species_scenario <- species_total_contribution_scenario %>%
  group_by(Scenario) %>%
  slice_max(order_by = Total_Contribution, n = 5)

bottom_5_species_scenario <- species_total_contribution_scenario %>%
  group_by(Scenario) %>%
  slice_min(order_by = Total_Contribution, n = 5)

# 🔹 Extract Trends for the Selected Species in Each Scenario
top_5_trends_scenario <- species_total_value_by_year_scenario %>% 
  filter(Species %in% top_5_species_scenario$Species)

bottom_5_trends_scenario <- species_total_value_by_year_scenario %>% 
  filter(Species %in% bottom_5_species_scenario$Species)

# 🔹 Plot **Top 5 Species Contributions Over Time** by Scenario
top_5_plot <- ggplot(top_5_trends_scenario, aes(x = Year, y = Annual_Economic_Contribution, color = Species)) +
  geom_line(size = 1.2) +
  facet_wrap(~Scenario, scales = "free_y") +
  ggtitle("Top 5 Species Contribution to Maine's Blue Economy by Scenario") +
  xlab("Year") + ylab("Total Economic Contribution ($)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"))

# Save the **Top 5 Contribution Plot by Scenario**
top_5_plot_file <- file.path(base_output_dir, "Top_5_Species_Contribution_By_Scenario.png")
ggsave(top_5_plot_file, plot = top_5_plot, width = 12, height = 6)
cat("Saved top 5 species contribution plot by scenario:", top_5_plot_file, "\n")

# 🔹 Plot **Bottom 5 Species Contributions Over Time** by Scenario
bottom_5_plot <- ggplot(bottom_5_trends_scenario, aes(x = Year, y = Annual_Economic_Contribution, color = Species)) +
  geom_line(size = 1.2) +
  facet_wrap(~Scenario, scales = "free_y") +
  ggtitle("Bottom 5 Species Contribution to Maine's Blue Economy by Scenario") +
  xlab("Year") + ylab("Total Economic Contribution ($)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"))

# Save the **Bottom 5 Contribution Plot by Scenario**
bottom_5_plot_file <- file.path(base_output_dir, "Bottom_5_Species_Contribution_By_Scenario.png")
ggsave(bottom_5_plot_file, plot = bottom_5_plot, width = 12, height = 6)
cat("Saved bottom 5 species contribution plot by scenario:", bottom_5_plot_file, "\n")


```

### Economic Growth by Species
```{r}
# Load species economic trends per scenario
species_trends_csv <- file.path(base_output_dir, "Species_Economic_Contribution_By_Year_By_Scenario.csv")
species_trends_scenario <- read.csv(species_trends_csv)

# 🔹 Ensure correct column names
print(colnames(species_trends_scenario))

# 🔹 Compute **Average Annual Percentage Change** Per Species for Each Scenario
species_change_scenario <- species_trends_scenario %>%
  group_by(Scenario, Species) %>%
  summarise(Average_Percent_Change = mean(Percent_Change, na.rm = TRUE)) %>%
  arrange(Scenario, desc(Average_Percent_Change))  # Rank by highest increase within each scenario

# Identify **Top 5 Growth and Bottom 5 Decline Species by Scenario**
top_5_growth_species_scenario <- species_change_scenario %>%
  group_by(Scenario) %>%
  slice_max(order_by = Average_Percent_Change, n = 5)

bottom_5_decline_species_scenario <- species_change_scenario %>%
  group_by(Scenario) %>%
  slice_min(order_by = Average_Percent_Change, n = 5)

# 🔹 Extract Trends for the Selected Species by Scenario
top_5_growth_trends_scenario <- species_trends_scenario %>%
  filter(Species %in% top_5_growth_species_scenario$Species)

bottom_5_decline_trends_scenario <- species_trends_scenario %>%
  filter(Species %in% bottom_5_decline_species_scenario$Species)

# 🔹 Plot **Top 5 Growing Species by Annual % Change for Each Scenario**
top_5_growth_plot <- ggplot(top_5_growth_trends_scenario, aes(x = Year, y = Percent_Change, color = Species)) +
  geom_line(size = 1.2) +
  facet_wrap(~Scenario, scales = "free_y") +
  ggtitle("Top 5 Species with Highest Annual Growth Rate by Scenario") +
  xlab("Year") + ylab("Annual Percent Change (%)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"))

# Save the **Top 5 Growth Rate Plot by Scenario**
top_5_growth_plot_file <- file.path(base_output_dir, "Top_5_Growth_Rate_Species_By_Scenario.png")
ggsave(top_5_growth_plot_file, plot = top_5_growth_plot, width = 12, height = 6)
cat("Saved top 5 species growth rate plot by scenario:", top_5_growth_plot_file, "\n")

# 🔹 Plot **Bottom 5 Declining Species by Annual % Change for Each Scenario**
bottom_5_decline_plot <- ggplot(bottom_5_decline_trends_scenario, aes(x = Year, y = Percent_Change, color = Species)) +
  geom_line(size = 1.2) +
  facet_wrap(~Scenario, scales = "free_y") +
  ggtitle("Bottom 5 Species with Highest Decline Rate by Scenario") +
  xlab("Year") + ylab("Annual Percent Change (%)") +
  xlim(2025, 2040) +  # Limit x-axis range
  theme_minimal() +
  theme(strip.text = element_text(size = 12, face = "bold"))

# Save the **Bottom 5 Declining Rate Plot by Scenario**
bottom_5_decline_plot_file <- file.path(base_output_dir, "Bottom_5_Declining_Rate_Species_By_Scenario.png")
ggsave(bottom_5_decline_plot_file, plot = bottom_5_decline_plot, width = 12, height = 6)
cat("Saved bottom 5 species decline rate plot by scenario:", bottom_5_decline_plot_file, "\n")

# 🔹 Save Ranked List of Species by **Average Annual % Change for Each Scenario**
species_change_scenario_csv <- file.path(base_output_dir, "Species_Annual_Percent_Change_By_Scenario.csv")
write.csv(species_change_scenario, species_change_scenario_csv, row.names = FALSE)
cat("Saved species annual percent change ranking by scenario:", species_change_scenario_csv, "\n")
```

## Validate Model
```{r}
 # Initialize list to store all species' evaluation results
all_evaluation_results <- list()

# Iterate through species directories
species_dirs <- list.dirs(base_output_dir, recursive = FALSE)

for (species_dir in species_dirs) {
  
  # Identify evaluation file
  eval_file <- file.path(species_dir, "Model_Evaluation.csv")
  
  if (file.exists(eval_file)) {
    
    # Read the evaluation results
    species_eval <- read.csv(eval_file)
    
    # Extract species name from directory
    species_name <- basename(species_dir)
    species_eval$Species <- species_name  # Add species name column
    
    # Store results
    all_evaluation_results[[species_name]] <- species_eval
  }
}

# Combine all species' results into a single dataframe
combined_evaluation_results <- bind_rows(all_evaluation_results)

# Save aggregated results
evaluation_csv_file <- file.path(base_output_dir, "All_Species_Model_Evaluation.csv")
write.csv(combined_evaluation_results, evaluation_csv_file, row.names = FALSE)

cat("Saved aggregated model evaluation results:", evaluation_csv_file, "\n")

```

```{r}
# Find best (highest R²) and worst (lowest R²) performing species for each model
top_10_species <- combined_evaluation_results %>%
  group_by(Model) %>%
  top_n(10, R2_Test) %>%
  arrange(Model, desc(R2_Test))

bottom_10_species <- combined_evaluation_results %>%
  group_by(Model) %>%
  top_n(-10, R2_Test) %>%
  arrange(Model, R2_Test)

# Save rankings
top_10_species_csv <- file.path(base_output_dir, "Top_10_Accurate_Species_Per_Model.csv")
bottom_10_species_csv <- file.path(base_output_dir, "Bottom_10_Accurate_Species_Per_Model.csv")

write.csv(top_10_species, top_10_species_csv, row.names = FALSE)
write.csv(bottom_10_species, bottom_10_species_csv, row.names = FALSE)

cat("Saved top 10 most accurate species per model:", top_10_species_csv, "\n")
cat("Saved bottom 10 least accurate species per model:", bottom_10_species_csv, "\n")
```

```{r}
# Top 10 Most Accurate Species (R²)
top_10_plot <- ggplot(top_10_species, aes(x = reorder(Species, -R2_Test), y = R2_Test, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  ggtitle("Top 10 Most Accurate Species Models (R²)") +
  xlab("Species") + ylab("R² (Higher is Better)") +
  theme_minimal()

top_10_plot_file <- file.path(base_output_dir, "Top_10_Accurate_Species.png")
ggsave(top_10_plot_file, plot = top_10_plot, width = 10, height = 6)
cat("Saved top 10 most accurate species plot:", top_10_plot_file, "\n")

# Bottom 10 Least Accurate Species (R²)
bottom_10_plot <- ggplot(bottom_10_species, aes(x = reorder(Species, R2_Test), y = R2_Test, fill = Model)) +
  geom_bar(stat = "identity", position = "dodge") +
  coord_flip() +
  ggtitle("Bottom 10 Least Accurate Species Models (R²)") +
  xlab("Species") + ylab("R² (Higher is Better)") +
  theme_minimal()

bottom_10_plot_file <- file.path(base_output_dir, "Bottom_10_Accurate_Species.png")
ggsave(bottom_10_plot_file, plot = bottom_10_plot, width = 10, height = 6)
cat("Saved bottom 10 least accurate species plot:", bottom_10_plot_file, "\n")

```
## Evaluate Results

### Relative Conditions: Assess Current Economic Trends using Most Popularly Fished Species
```{r}
# Subset Results
colnames(interpolated_data)[colnames(interpolated_data) == "species"] <- "Species"

# Define the species list of interest
known_top_species <- c("Lobster American", "Menhaden Atlantic", "Clam Soft", "Elver", "Seaweed Unc", "Scallop Sea", "Alewife", "Oysters", "Pollock", "Flounder Yellowtail", 
                       "Haddock", "Flounder Winter", "Mussel Blue Sea")

selected_species_forecast <- master_results_df %>%
  filter(Species %in% known_top_species, Scenario == "Baseline")

# Prepare Historic Data
historic_data <- interpolated_data %>%
  filter(Species %in% known_top_species) %>%
  dplyr::select(Year, Species, Total_Weight_kg, Avg_Market_Price, Total_Value) %>%
  mutate(Data_Source = "Historic")

# Rename columns for merging
model_data <- selected_species_forecast %>%
  dplyr::select(Year, Species, Predicted_Landings, Predicted_Market_Value, Predicted_Blue_Economy_Value) %>%
  rename(Total_Weight_kg = Predicted_Landings,
         Avg_Market_Price = Predicted_Market_Value,
         Total_Value = Predicted_Blue_Economy_Value) %>%
  mutate(Data_Source = "Projected")

# Combine datasets without gaps
combined_data <- bind_rows(historic_data, model_data) %>%
  arrange(Species, Year)

# Plot with continuous connection - Landings (Log Scale)
ggplot(combined_data, aes(x = Year, y = Total_Weight_kg, color = Species, linetype = Data_Source)) +
  geom_line(size = 1.2) +
  geom_vline(xintercept = 2020, linetype = "dashed", color = "grey", size = 1.0) +
  labs(title = "Total Landings Over Time (Historic & Projected)",
       x = "Year", 
       y = "Total Landings (kg)") +
  scale_linetype_manual(values = c("Historic" = "solid", "Projected" = "dotted", "Interpolated" = "dotted")) +
  theme_minimal()

# Plot Market Price Over Time (Log Scale)
ggplot(combined_data, aes(x = Year, y = Avg_Market_Price, color = Species, linetype = Data_Source)) +
  geom_line(size = 1.2) +
  geom_vline(xintercept = 2020, linetype = "dashed", color = "grey", size = 1.0) +
  labs(title = "Market Price Over Time (Historic & Projected)",
       x = "Year", 
       y = "Market Price ($/kg") +
  scale_linetype_manual(values = c("Historic" = "solid", "Projected" = "dotted")) +
  theme_minimal()

# Plot Total Economic Value Over Time (Log Scale)
ggplot(combined_data, aes(x = Year, y = Total_Value, color = Species, linetype = Data_Source)) +
  geom_line(size = 1.2) +
  geom_vline(xintercept = 2020, linetype = "dashed", color = "grey", size = 1.0) +
  labs(title = "Total Economic Value Over Time (Historic & Projected)",
       x = "Year", 
       y = "Total Value ($)") +
  scale_linetype_manual(values = c("Historic" = "solid", "Projected" = "dotted")) +
  theme_minimal()

```

### Evaluate Change in Net Economic Value over Time

### Identify Comparable Economic Species to Diversify Stocks
- Market Price
- could be lots of landings available at moderate price
- fewer landings at higher price

### Evaluate Projected Net Economic Value over Time with Diversified Stock