---
title: "Model Structure Brainstorming"
author: "Vanessa Quintana"
date: "`r Sys.Date()`"
output: html_document
---

# Brainstorming Model Inputs
- landings by pound and by value from 1950-2019 (overall abundance and economic value)
- lobster landings by county for pound and value (ties abundance to reginal economic importance)
- 

## Input Data

### DMR Landings for Species 1950-2019
```{r}
rm(list = ls())  # Clears all objects from the environment

# Load necessary libraries
library(tidyverse)
library(forecast)
library(ggplot2)
library(dplyr)
library(lubridate)
library(tidyr)
library(caret)
library(tseries)
library(Metrics)
library(zoo)
library(stringdist)

# Load historical data (1950-2019)
landings <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/MaineDMR_Landings_Time_Series_Data_2025-03-10.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(landings)
str(landings)
summary(landings)

# Market Price per Kilogram
landings$market_price_per_Kg <- landings$total_value / landings$total_weight
```

### Lobster Landings by County in pounds and value
```{r}
# Load historical data (1950-2019)
lobster_County <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/LobByCntyMoZone.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(lobster_County)
str(lobster_County)
summary(lobster_County)
```


### NOAA Tides and Currents Water Levels Monthly Eastport, Portland, Bar Harbor, Maine.
```{r}
# Load Historical Water Level Data

# Load Portland, ME Water Level Data
portland <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Portland_Historic_Water_Levels.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(portland)
str(portland)
summary(portland)

# Load Portland, ME Water Level Data
eastport <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Eastport_Historic_Water_Levels.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(eastport)
str(eastport)
summary(eastport)

# Load Portland, ME Water Level Data
barharbor <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Bar_Harbor_Historic_Water_Levels.csv",
                     stringsAsFactors = FALSE)

# Inspect data
head(barharbor)
str(barharbor)
summary(barharbor)

# Function to clean and process water level data
clean_water_levels <- function(df, station_name) {
  df <- df %>%
    dplyr::mutate(Date = as.Date(Date, format="%Y/%m/%d"),
           Year = year(Date)) %>%
    dplyr::select(Year, MSL..ft.) %>%
    dplyr::rename(Mean_Sea_Level_ft = MSL..ft.) %>%
    dplyr::group_by(Year) %>%
    dplyr::summarize(Mean_Sea_Level_ft = mean(Mean_Sea_Level_ft, na.rm = TRUE)) %>%
    dplyr::mutate(Station = station_name)
  
  return(df)
}

# Apply function to each station
portland_clean <- clean_water_levels(portland, "Portland")
eastport_clean <- clean_water_levels(eastport, "Eastport")
barharbor_clean <- clean_water_levels(barharbor, "Bar Harbor")

# Combine all stations
water_levels <- bind_rows(portland_clean, eastport_clean, barharbor_clean)

# Convert feet to meters (1 ft = 0.3048 m)
water_levels <- water_levels %>%
  mutate(Mean_Sea_Level_m = Mean_Sea_Level_ft * 0.3048)

# Preview cleaned water levels
head(water_levels)
```

### NOAA Oceanic Nino Index (ONI)
```{r}
# If the data is tab-separated, use:
enso_data <- read.table("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/NOAA_ONI.txt", header = TRUE, sep = "", stringsAsFactors = FALSE)

# Convert to numeric
enso_data$Anomaly <- as.numeric(enso_data$ANOM)

# Categorize ENSO Phases
enso_data <- enso_data %>%
  mutate(ENSO_Phase = case_when(
    Anomaly > 0.5 ~ "El Niño",
    Anomaly < -0.5 ~ "La Niña",
    TRUE ~ "Neutral"
  ))

# Inspect data
head(enso_data)
str(enso_data)
summary(enso_data)

```

### NOAA North Atlantic Oscillation Index
```{r}
# If the data is tab-separated, use:
NAO_data <- read.table("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/NAO_Index_NOAA.txt", header = TRUE, stringsAsFactors = FALSE)

# Convert row names into an actual column
NAO_data <- NAO_data %>%
  rownames_to_column(var = "Year")  # Moves row names to a column called "Year"

# Convert Year to numeric
NAO_data$Year <- as.numeric(NAO_data$Year)

NAO_long <- NAO_data %>%
  pivot_longer(cols = -Year, names_to = "Month", values_to = "NAO_Index") %>%
  drop_na

# Inspect data
head(NAO_data)
str(NAO_data)
summary(NAO_data)

```

### NOAA Stock Assessment Data
```{r}
# Load Stock Assessment Data
stocks <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Assessment_TimeSeries_Data.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Save original column names to extract species names
original_colnames <- colnames(stocks)

# Extract species names (taking first two words, assuming "Atlantic cod" or "White hake" style)
species_names <- sub("^(\\w+\\.\\w+).*", "\\1", original_colnames)
species_names <- gsub("\\.", " ", species_names)  # Replace dots with spaces for readability

# Extract stock assessment variable names (everything after first "..")
stock_variables <- sub("^.*?\\.\\.\\.", "", original_colnames)

# Rename columns with extracted species and variable names
colnames(stocks) <- paste(species_names, stock_variables, sep = "_")

# Combine species names with row 1 and row 4 for new column names
new_colnames <- paste(species_names, stocks[3, ], stocks[6, ], sep = "_")

# Assign new column names
colnames(stocks) <- new_colnames

# Save the first column's name before removing it
year_colname <- colnames(stocks)[1]

# Remove the first column (year column temporarily)
stocks <- stocks[, -1]  

# Remove rows 1, 2, and 4 (including extra metadata rows)
stocks <- stocks[-c(1:7), ]

# Reassign the saved year column name to the first column
colnames(stocks)[1] <- year_colname

# Identify rows where all columns except the first are empty
stocks <- stocks[-c(1:20), ]

stocks <- stocks %>%
  mutate(across(everything(), ~ as.numeric(.)))

# Reset row indices
rownames(stocks) <- NULL

# Function to interpolate numeric columns
interpolate_numeric <- function(x) {
  if (is.numeric(x)) {
    return(na.approx(x, rule = 2))  # Linear interpolation
  } else {
    return(x)  # Return as is if not numeric
  }
}

# Apply interpolation to numeric columns
interpolated_stocks <- stocks %>%
  mutate(across(where(is.numeric), interpolate_numeric))

# Manually clean known variable names for clarity
stock_variables <- str_replace_all(stock_variables, "Reported Catch - Total \\(Mean\\)", "Total Catch")
stock_variables <- str_replace_all(stock_variables, "Total F, Ages 5-7 \\(Mean\\)", "Mean F, Ages 5-7")
stock_variables <- str_replace_all(stock_variables, "Mature Biomass \\(Mean\\)", "Mature Biomass")
stock_variables <- str_replace_all(stock_variables, "Abundance, Age 1 \\(Mean\\)", "Age 1 Abundance")
stock_variables <- str_replace_all(stock_variables, "Catch - Landings \\+ Commercial Discards", "Total Landings + Discards")

# Extract year from Variable (assuming yyyy_Total Catch format)
stocks_long <- interpolated_stocks %>%
  pivot_longer(cols = -1, names_to = "Stock_Variable", values_to = "Value") %>%
  separate(Stock_Variable, into = c("species", "Variable"), sep = "_", extra = "merge")  # Split into two columns

# Extract year from Variable (assuming yyyy_Total Catch format)
colnames(stocks_long)[colnames(stocks_long) == "Stock Name_Assessment Year_Description"] <- "Year"

# Convert Year to numeric
stocks_total_catch <- stocks_long %>%
  mutate(Year = as.numeric(Year))

stocks_total_catch <- stocks_total_catch %>%
  mutate(Value = as.numeric(Value))

unique(stocks_long$Variable)  # See all unique variable names

# Keep only "Total Catch"
stocks_total_catch <- stocks_total_catch %>%
  dplyr::filter(str_detect(Variable, "Total Catch|Estimated Commercial Catch")) %>%
  dplyr::select(Year, species, Value)  # Keep only relevant columns

colnames(stocks_total_catch)[colnames(stocks_total_catch) == "Value"] <- "Total_Catch"

# Inspect cleaned dataset
head(stocks_total_catch, 10)
str(stocks_total_catch)
summary(stocks_total_catch)
```

### Monthly Mean Average Temperature
```{r}
## Portland
# Load Temperature Data Weather.gov
portland_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Portland_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(portland_temp)
head(portland_temp, 10)
str(portland_temp)
summary(portland_temp)

# Load Precipitation Data
Portland_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Portland_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(Portland_precip)
head(Portland_precip, 10)
str(Portland_precip)
summary(Portland_precip)

## Belfast
# Load Temperature Data Weather.gov
belfast_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Belfast_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(belfast_temp)
head(belfast_temp, 10)
str(belfast_temp)
summary(belfast_temp)

# Load Precipitation Data
belfast_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Belfast_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(belfast_precip)
head(belfast_precip, 10)
str(belfast_precip)
summary(belfast_precip)

## Moosehead
# Load Temperature Data Weather.gov
moosehead_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Moosehead_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(moosehead_temp)
head(moosehead_temp, 10)
str(moosehead_temp)
summary(moosehead_temp)

# Load Precipitation Data
moosehead_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Moosehead_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(moosehead_precip)
head(moosehead_precip, 10)
str(moosehead_precip)
summary(moosehead_precip)

## Gardiner
# Load Temperature Data Weather.gov
gardiner_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Gardiner_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(gardiner_temp)
head(gardiner_temp, 10)
str(gardiner_temp)
summary(gardiner_temp)

# Load Precipitation Data
gardiner_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Gardiner_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(gardiner_precip)
head(gardiner_precip, 10)
str(gardiner_precip)
summary(gardiner_precip)

## Augusta
# Load Temperature Data Weather.gov
augusta_temp <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Augusta_Monthly_Avg_Temp.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(augusta_temp)
head(augusta_temp, 10)
str(augusta_temp)
summary(augusta_temp)

# Load Precipitation Data
augusta_precip <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Augusta_Monthly_Avg_Precipitation.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Inspect data
colnames(augusta_precip)
head(augusta_precip, 10)
str(augusta_precip)
summary(augusta_precip)

convert_to_numeric <- function(df) {
  df[] <- lapply(df, function(x) as.numeric(as.character(x)))  # Convert all columns to numeric
  return(df)
}

# Portland
portland_temp <- convert_to_numeric(portland_temp)
Portland_precip <- convert_to_numeric(Portland_precip)

# Belfast
belfast_temp <- convert_to_numeric(belfast_temp)
belfast_precip <- convert_to_numeric(belfast_precip)

# Moosehead
moosehead_temp <- convert_to_numeric(moosehead_temp)
moosehead_precip <- convert_to_numeric(moosehead_precip)

# Gardiner
gardiner_temp <- convert_to_numeric(gardiner_temp)
gardiner_precip <- convert_to_numeric(gardiner_precip)

# Augusta
augusta_temp <- convert_to_numeric(augusta_temp)
augusta_precip <- convert_to_numeric(augusta_precip)

```

### Maine Population Levels
```{r}
# Read in state-level population data
state_population <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/State_Population.csv",
                             stringsAsFactors = FALSE, check.names = TRUE)

# Convert wide format to long format
state_population_long <- state_population %>%
  pivot_longer(cols = starts_with("A00AA"), names_to = "Year", values_to = "Population") %>%
  mutate(Year = as.numeric(gsub("A00AA", "", Year))) %>%
  filter(Year >= 1950 & Year <= 2020)  # Keep only relevant years

# Interpolate missing years
state_population_interp <- state_population_long %>%
  complete(Year = full_seq(Year, 1)) %>%  # Fill missing years
  arrange(Year) %>%
  mutate(Population = zoo::na.approx(Population, na.rm = FALSE, rule = 2))  # Linear interpolation

# Read in county-level population data
county_population <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/County_Populations.csv",
                              stringsAsFactors = FALSE, check.names = TRUE)

# Convert wide format to long format
county_population_long <- county_population %>%
  pivot_longer(cols = starts_with("A00AA"), names_to = "Year", values_to = "Population") %>%
  mutate(Year = as.numeric(gsub("A00AA", "", Year))) %>%
  filter(Year >= 1950 & Year <= 2020)  # Keep only relevant years

# Interpolate missing years
county_population_interp <- county_population_long %>%
  complete(Year = full_seq(Year, 1), nesting(COUNTY)) %>%  # Fill missing years for each county
  arrange(COUNTY, Year) %>%
  group_by(COUNTY) %>%
  mutate(Population = zoo::na.approx(Population, na.rm = FALSE, rule = 2))  # Linear interpolation

# Save results
write.csv(state_population_interp, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/State_Population_Annual.csv", row.names = FALSE)
write.csv(county_population_interp, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/County_Population_Annual.csv", row.names = FALSE)

# Preview output
head(state_population_interp)
head(county_population_interp)

# Subset county-level population data
county_population_subset <- county_population_interp %>%
  dplyr::select(Year, COUNTY, Population)

# Subset state-level population data
state_population_subset <- state_population_interp %>%
  dplyr::select(Year, Population)

# Save the new subsets as CSV files
write.csv(county_population_subset, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/County_Population_Subset.csv", row.names = FALSE)
write.csv(state_population_subset, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/State_Population_Subset.csv", row.names = FALSE)

# Preview the subsets
head(county_population_subset)
head(state_population_subset)
```

### Historical GDP

```{r}
GDP <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Historical_GDP.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

head(GDP)

# Extract only the year from the Date column
gdp_data_cleaned <- GDP %>%
  dplyr:: mutate(Year = year(mdy(Date))) %>%  # Convert date and extract year
  dplyr::filter(Year >= 1950 & Year <= 2020) %>%  # Keep only years 1950-2020
  dplyr::select(Year, GDP..Billions.of.US..., Per.Capita..US..., Annual...Change)  # Keep relevant columns

# Save the cleaned dataset
write.csv(gdp_data_cleaned, "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/GDP_Data_Cleaned.csv", row.names = FALSE)

# Preview the cleaned data
head(gdp_data_cleaned)
```

### Per Capita Consumption

```{r}
consumption <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Per_Captia_Consumption.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

head(consumption)
```

### Fisheries Exports

```{r}
# Load the data from CSV
exports <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/Historical_Fisheries_Exports.csv",
                    stringsAsFactors = FALSE, 
                    check.names = FALSE, 
                    skip = 0)  # Skip no rows initially

# Transpose the data so that rows become columns
exports <- t(exports)

# Convert the transposed matrix to a data frame
exports_df <- as.data.frame(exports, stringsAsFactors = FALSE)

# Ensure that we are only converting the numeric data columns
exports_df[] <- lapply(exports_df, function(x) as.numeric(as.character(x)))

# Set the first row as the column names
colnames(exports_df) <- exports_df[1, ]

# Remove the first row (which is now redundant)
exports_df <- exports_df[-1, ]
rownames(exports_df) <- NULL

# Rename the columns to make the first one "Fishery_Exports" and the second one "Year"
colnames(exports_df)[1] <- "Fishery_Exports"
colnames(exports_df)[2] <- "Year"

# View the first few rows of the data frame to ensure everything is correct
head(exports_df)
```


## Preprocessing

### Sea- Level

```{r}
ggplot(water_levels, aes(x = Year, y = Mean_Sea_Level_m, color = Station)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +  # Linear trend
  labs(title = "Historical Mean Sea Level Trends in Maine",
       y = "Mean Sea Level (m)", x = "Year") +
  theme_minimal()

```
```{r}
# Fit linear regression model for each station
linear_models <- water_levels %>%
  group_by(Station) %>%
  do(model = lm(Mean_Sea_Level_m ~ Year, data = .))

# Extract slope (sea level rise rate) for each station
slopes <- linear_models %>%
  summarise(Station, Rate_m_per_year = coef(model)[2])

print(slopes)

```


### Landings and Value

```{r}
# Aggregate total landings per year for each species
landings_yearly <- landings %>%
  group_by(year, species) %>%
  summarize(Total_Weight_kg = sum(total_weight, na.rm = TRUE),
            Total_Value = sum(total_value, na.rm = TRUE),
            Avg_Market_Price = mean(market_price_per_Kg)) %>%
  ungroup()  # Ensure no lingering groupings

# Inspect results
head(landings_yearly)

```

### Lobster Landings

```{r}
# Set the first row as row names
colnames(lobster_County) <- lobster_County[1, ]

# Remove the first row from the dataset
lobster_County <- lobster_County[-1, ]

# Reset row indices
rownames(lobster_County) <- NULL

# Inspect the cleaned dataset
head(lobster_County)

# Convert Year to integer
lobster_County$Year <- as.integer(lobster_County$Year)

# Convert Pounds and Value to numeric (removing any commas)
lobster_County <- lobster_County %>%
  mutate(
    Pounds = as.numeric(gsub(",", "", Pounds)), 
    Value = as.numeric(gsub(",", "", Value))
  )

# Now summarize by Year and County
lobster_summary <- lobster_County %>%
  group_by(Year, County) %>%
  summarize(
    Total_Pounds = sum(Pounds, na.rm = TRUE),
    Total_Value = sum(Value, na.rm = TRUE)
  )

# Inspect the results
head(lobster_summary)

colnames(landings_yearly)[colnames(landings_yearly) == "year"] <- "Year"
colnames(lobster_summary)[colnames(lobster_summary) == "Total_Pounds"] <- "Lobster_Pounds"
colnames(lobster_summary)[colnames(lobster_summary) == "Total_Value"] <- "Lobster_Value"

# Ensure Year is numeric in all datasets
landings_yearly$Year <- as.integer(landings_yearly$Year)
lobster_summary$Year <- as.integer(lobster_summary$Year)
water_levels$Year <- as.integer(water_levels$Year)

# Merge Landings Data with Lobster Data (preserving county information)
merged_data <- landings_yearly  %>%
  left_join(lobster_summary, by = "Year")

# Merge with sea level data (averaging across stations)
merged_data <- merged_data %>%
  left_join(water_levels %>%
              group_by(Year) %>%
              summarize(Mean_Sea_Level_m = mean(Mean_Sea_Level_m, na.rm = TRUE)),
            by = "Year")

# Preview the merged dataset
head(merged_data)

# Check for any missing values
summary(merged_data)

```

### ENSO Data

```{r}

# Ensure Year is an integer
enso_data$Year <- as.integer(enso_data$YR)

# Summarize by Year: Identify the dominant ENSO phase per year
dominant_enso <- enso_data %>%
  dplyr::group_by(Year, ENSO_Phase) %>%
  dplyr::summarise(Count = n(), .groups = "drop") %>%  # Count occurrences of each phase per year
  dplyr::arrange(Year, desc(Count)) %>%  # Sort by Year and Count (descending)
  dplyr::distinct(Year, .keep_all = TRUE) %>%  # Keep only the most frequent ENSO phase per year
  dplyr::select(Year, ENSO_Phase)  # Keep only relevant columns

# Merge dominant ENSO phase with merged_data
merged_data <- merged_data %>%
  left_join(dominant_enso, by = "Year")

# Inspect results
head(merged_data)
```

### Temperature and Precipitation Data

```{r}
## Portland
# Convert Year column
portland_temp$Year <- as.integer(portland_temp$Year)
Portland_precip$Year <- as.integer(Portland_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
portland_temp <- portland_temp %>%
  rename(Portland_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
Portland_precip <- Portland_precip %>%
  rename(Portland_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(portland_temp %>% dplyr::select(Year, Portland_Annual_Temp), by = "Year") %>%
  left_join(Portland_precip %>% dplyr::select(Year, Portland_Annual_Precip), by = "Year")

## Belfast
# Convert Year column
belfast_temp$Year <- as.integer(belfast_temp$Year)
belfast_precip$Year <- as.integer(belfast_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
belfast_temp <- belfast_temp %>%
  rename(Belfast_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
belfast_precip <- belfast_precip %>%
  rename(Belfast_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(belfast_temp %>% dplyr::select(Year, Belfast_Annual_Temp), by = "Year") %>%
  left_join(belfast_precip %>% dplyr::select(Year, Belfast_Annual_Precip), by = "Year")

## Moosehead
# Convert Year column
moosehead_temp$Year <- as.integer(moosehead_temp$Year)
moosehead_precip$Year <- as.integer(moosehead_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
moosehead_temp <- moosehead_temp %>%
  rename(Moosehead_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
moosehead_precip <- moosehead_precip %>%
  rename(Moosehead_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(moosehead_temp %>% dplyr::select(Year, Moosehead_Annual_Temp), by = "Year") %>%
  left_join(moosehead_precip %>% dplyr::select(Year, Moosehead_Annual_Precip), by = "Year")

## Gardnier
# Convert Year column
gardiner_temp$Year <- as.integer(gardiner_temp$Year)
gardiner_precip$Year <- as.integer(gardiner_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
gardiner_temp <- gardiner_temp %>%
  rename(Gardiner_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
gardiner_precip <- gardiner_precip %>%
  rename(Gardiner_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(gardiner_temp %>% dplyr::select(Year, Gardiner_Annual_Temp), by = "Year") %>%
  left_join(gardiner_precip %>% dplyr::select(Year, Gardiner_Annual_Precip), by = "Year")

## Augusta
# Convert Year column
augusta_temp$Year <- as.integer(augusta_temp$Year)
augusta_precip$Year <- as.integer(augusta_precip$Year)

# Rename the 'Annual' column in the temperature dataset to 'Annual_Temp'
augusta_temp <- augusta_temp %>%
  rename(Augusta_Annual_Temp = Annual)

# Rename the 'Annual' column in the precipitation dataset to 'Annual_Precip'
augusta_precip <- augusta_precip %>%
  rename(Augusta_Annual_Precip = Annual)

# Merge temperature and precipitation data
merged_data <- merged_data %>%
  left_join(augusta_temp %>% dplyr::select(Year, Augusta_Annual_Temp), by = "Year") %>%
  left_join(augusta_precip %>% dplyr::select(Year, Augusta_Annual_Precip), by = "Year")

# Replace any "M" values with NA
merged_data[merged_data == "M"] <- NA

head(merged_data)
summary(merged_data)
```

### North Atlantic Oscillation Index
```{r}
# Compute annual mean NAO index
NAO_annual <- NAO_long %>%
  group_by(Year) %>%
  summarize(Annual_NAO = mean(NAO_Index, na.rm = TRUE))  # Average across months

# Merge NAO data with existing merged_data
merged_data <- merged_data %>%
  left_join(NAO_annual, by = "Year")  # Match based on Year column

# Check merged dataset
head(merged_data)
```

### Historic GDP

```{r}
# Merge GDP data with existing merged_data
merged_data <- merged_data %>%
  left_join(gdp_data_cleaned, by = "Year")  # Match based on Year column

```

### Per Capita Consumption

```{r}
# Merge GDP data with existing merged_data
merged_data <- merged_data %>%
  left_join(consumption, by = "Year")  # Match based on Year column
```

### Maine Population
```{r}
colnames(state_population_subset)[colnames(state_population_subset) == "Population"] <- "State_Population"

# Merge State Population data with existing merged_data
merged_data <- merged_data %>%
  left_join(state_population_subset, by = "Year")  # Match based on Year column

colnames(county_population_subset)[colnames(county_population_subset) == "COUNTY"] <- "County"
colnames(county_population_subset)[colnames(county_population_subset) == "Population"] <- "County_Population"

# Remove the word "County" from the County column
#county_population_subset$County <- gsub(" County", "", county_population_subset$County)

# Display the first few rows to verify the change
#head(county_population_subset)

# Merge GDP data with existing merged_data
#merged_data <- merged_data %>%
#  left_join(county_population_subset, by = c("Year", "County"))  # Match based on Year column
```

### Fisheries Exports

```{r}
# Merge Export data with existing merged_data

merged_data <- merged_data %>%
  left_join(exports_df, by = "Year")  # Match based on Year column

merged_data$Fishery_Exports <- ifelse(merged_data$Fishery_Exports == 0, NA, merged_data$Fishery_Exports)

```

### Interpolate Missing Values

```{r}
# Interpolate NA Values
head(merged_data,10)

# Function to interpolate numeric columns
interpolate_numeric <- function(x) {
  if (is.numeric(x)) {
    return(na.approx(x, rule = 2))  # Linear interpolation
  } else {
    return(x)  # Return as is if not numeric
  }
}

# Apply interpolation to numeric columns
interpolated_data <- merged_data %>%
  mutate(across(where(is.numeric), interpolate_numeric))

# Fill missing categorical values using last observation carried forward
interpolated_data <- interpolated_data %>%
  mutate(across(where(is.character), ~na.locf(.x, na.rm = FALSE)))

```

### Stock Assessment

```{r}

#species_list1 <- unique(interpolated_data$species)
#print(species_list1)
#species_list2 <- unique(stocks_total_catch$species)
#print(species_list2)

# Function to clean species names
#clean_species_name <- function(species) {
#  species <- str_trim(species)  # Remove extra spaces
#  species <- str_remove(species, "Gulf of Maine.*")  # Remove extra descriptors
#  species <- str_remove(species, "Georges Bank.*")   # Remove extra descriptors
#  species <- str_remove(species, "\\d+$")           # Remove trailing numbers
#  return(species)
#}

# Apply cleaning function
#species_list2_clean <- unique(sapply(species_list2, clean_species_name))

# Function to find closest match
#find_closest_match <- function(species, species_list) {
#  if (is.na(species) || species == "") return(NA)  # Handle missing values
#  
#  distances <- stringdist(species, species_list, method = "jw")  # Jaro-Winkler similarity
#  closest_index <- which.min(distances)  # Get closest match
#  return(species_list[closest_index])  # Return best match
#}

# Apply matching function
#matched_species <- vapply(species_list2_clean, find_closest_match, character(1), species_list = species_list1)

# Create a lookup table
#species_mapping <- data.frame(Original_Species = species_list2_clean, Matched_Species = matched_species)

# Inspect mapping
#print(species_mapping)

# Ensure stocks_long species names match cleaned species list
#stocks_total_catch$Cleaned_Species <- sapply(stocks_total_catch$species, clean_species_name)

# Merge with fuzzy-matched species names
#stocks_total_catch <- stocks_total_catch %>%
#  left_join(species_mapping, by = c("Cleaned_Species" = "Original_Species"))

# Replace with matched species name
#stocks_total_catch$species <- stocks_total_catch$Matched_Species

# Drop temporary columns
#stocks_total_catch <- stocks_total_catch %>% dplyr::select(-Cleaned_Species, -Matched_Species)

# Verify changes
#head(stocks_total_catch)

#interpolated_data <- interpolated_data %>%
#  left_join(stocks_total_catch, by = c("Year", "species"))

# Check for missing matches
#summary(interpolated_data)

```

## Forecast Results

```{r}
#install.packages("vars")
#install.packages("BVAR")

colnames(interpolated_data)

# Set forecast years (2025-2100)
future_years <- seq(2020, 2040, by = 1)

# Convert ENSO Phase to Numeric
interpolated_data$ENSO_Phase <- ifelse(interpolated_data$ENSO_Phase == "El Niño", 1,
                                       ifelse(interpolated_data$ENSO_Phase == "La Niña", -1, 0))

head(interpolated_data,20)

# Get unique species
species_list <- unique(interpolated_data$species)
print(species_list)

```


### Sea-Level Rise Scenarios
```{r}
# Predict baseline sea levels (historical trend)
slr_model <- lm(Mean_Sea_Level_m ~ Year, data = interpolated_data)
baseline_sea_levels <- predict(slr_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Sea Level Rise Adjustments
low_slr <- baseline_sea_levels + (0.11 * ((future_years - 2020) / (2040 - 2020))^2)  # SSP1-2.6 (~0.44m by 2100)
moderate_slr <- baseline_sea_levels + (0.15 * ((future_years - 2020) / (2040 - 2020))^2)  # SSP2-4.5 (~0.60m by 2100)
high_slr <- baseline_sea_levels + (0.25 * ((future_years - 2020) / (2040 - 2020))^2)  # SSP5-8.5 (~1.0m by 2100)

# Create DataFrame for SLR Scenarios
slr_data <- data.frame(
  Year = rep(future_years, times = 3),
  SLR = c(low_slr, moderate_slr, high_slr),
  Scenario = rep(c("Low SLR", "Moderate SLR", "High SLR"), each = length(future_years))
)

# Plot SLR Scenarios
ggplot(slr_data, aes(x = Year, y = SLR, color = Scenario)) +
  geom_line(size = 1) +
  labs(title = "Projected Sea Level Rise Scenarios (2020-2040)",
       x = "Year", y = "Sea Level Rise (m)") +
  theme_minimal()

```

### Warming Scenarios
```{r}
## Portland

# Generate warming scenarios (based on temperature trends)
portland_temp_model <- lm(Portland_Annual_Temp ~ Year, data = interpolated_data)
portland_baseline_temp <- predict(portland_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
portland_low_temp <- portland_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
portland_moderate_temp <- portland_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
portland_high_temp <- portland_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
portland_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(portland_low_temp, portland_moderate_temp, portland_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(portland_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Portland, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()

## Belfast

# Generate warming scenarios (based on temperature trends)
belfast_temp_model <- lm(Belfast_Annual_Temp ~ Year, data = interpolated_data)
belfast_baseline_temp <- predict(belfast_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
belfast_low_temp <- belfast_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
belfast_moderate_temp <- belfast_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
belfast_high_temp <- belfast_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
belfast_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(belfast_low_temp, belfast_moderate_temp, belfast_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(belfast_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Belfast, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()

## Moosehead

# Generate warming scenarios (based on temperature trends)
moosehead_temp_model <- lm(Moosehead_Annual_Temp ~ Year, data = interpolated_data)
moosehead_baseline_temp <- predict(moosehead_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
moosehead_low_temp <- moosehead_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
moosehead_moderate_temp <- moosehead_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
moosehead_high_temp <- moosehead_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
moosehead_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(moosehead_low_temp, moosehead_moderate_temp, moosehead_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(moosehead_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Moosehead, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()

## Gardiner

# Generate warming scenarios (based on temperature trends)
gardiner_temp_model <- lm(Gardiner_Annual_Temp ~ Year, data = interpolated_data)
gardiner_baseline_temp <- predict(gardiner_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
gardiner_low_temp <- gardiner_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
gardiner_moderate_temp <- gardiner_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
gardiner_high_temp <- gardiner_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
gardiner_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(gardiner_low_temp, gardiner_moderate_temp, gardiner_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(gardiner_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Gardiner, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()

## Augusta

# Generate warming scenarios (based on temperature trends)
augusta_temp_model <- lm(Augusta_Annual_Temp ~ Year, data = interpolated_data)
augusta_baseline_temp <- predict(augusta_temp_model, newdata = data.frame(Year = future_years))

# IPCC AR6-Based Temperature Adjustments
augusta_low_temp <- augusta_baseline_temp + (0.45 * ((future_years - 2020) / (2040 - 2020)))  # SSP1-2.6 (~1.8°C increase by 2100)
augusta_moderate_temp <- augusta_baseline_temp + (0.675 * ((future_years - 2020) / (2040 - 2020)))  # SSP2-4.5 (~2.7°C increase by 2100)
augusta_high_temp <- augusta_baseline_temp + (1.1 * ((future_years - 2020) / (2040 - 2020)))  # SSP5-8.5 (~4.4°C increase by 2100)

# Create DataFrame for Temperature Scenarios
augusta_temp_data <- data.frame(
  Year = rep(future_years, times = 3),
  Temperature = c(augusta_low_temp, augusta_moderate_temp, augusta_high_temp),
  Scenario = rep(c("Low Warming", "Moderate Warming", "High Warming"), each = length(future_years))
)

# Plot Temperature Warming Scenarios
ggplot(augusta_temp_data, aes(x = Year, y = Temperature, color = Scenario)) +
  geom_line(linewidth = 1) +
  labs(title = "Projected Temperature Warming Scenarios Augusta, ME (2020-2040)",
       x = "Year", y = "Temperature (°C)") +
  theme_minimal()
```

### ENSO Scenarios
```{r}
set.seed(42)  # Ensure reproducibility

# Use future_years (2020-2100)
enso_2yr_future <- sin(2 * pi * (future_years - min(future_years)) / 2)  # 2-year cycle
enso_3yr_future <- sin(2 * pi * (future_years - min(future_years)) / 3)  # 3-year cycle
enso_5yr_future <- sin(2 * pi * (future_years - min(future_years)) / 5)  # 5-year cycle
enso_7yr_future <- sin(2 * pi * (future_years - min(future_years)) / 7)  # 7-year cycle

# Combine into a dataframe
enso_scenarios <- data.frame(
  Year = future_years,
  ENSO_2yr = enso_2yr_future,
  ENSO_3yr = enso_3yr_future,
  ENSO_5yr = enso_5yr_future,
  ENSO_7yr = enso_7yr_future
)

# Visualize ENSO cycles for the future period (2020-2100)
enso_scenarios %>%
  pivot_longer(cols = starts_with("ENSO"), names_to = "Cycle", values_to = "Index") %>%
  ggplot(aes(x = Year, y = Index, color = Cycle)) +
  geom_line(linewidth = 1) +
  theme_minimal() +
  labs(title = "Simulated ENSO Cycles (2020-2100)", y = "ENSO Index", x = "Year")

```

### Export Trends
```{r}
#export_model

```

### NAO Index
```{r}
# Generate a simple trend model for Annual_NAO
nao_model <- lm(Annual_NAO ~ Year, data = interpolated_data)

# Predict baseline NAO for future years
future_annual_nao <- predict(nao_model, newdata = data.frame(Year = future_years))

```

### Population Trends
```{r}
# Generate a simple trend model for state_population
state_population_model <- lm(State_Population ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_state_population <- predict(state_population_model, newdata = data.frame(Year = future_years))

## By country
# Generate a simple trend model for state_population
civilian_population_model <- lm(Civilian.Population..Millions. ~ Year, data = interpolated_data)

# Predict baseline state_population for future years
future_Civilian.Population..Millions. <- predict(civilian_population_model, newdata = data.frame(Year = future_years))
```

### All Scenarios
```{r}
colnames(interpolated_data)
# Create scenario-specific datasets with NAO included
future_scenarios <- list(
  # Baseline Scenario
# Baseline Scenario
"Baseline" = data.frame(
  Year = future_years, 
  Mean_Sea_Level_m = baseline_sea_levels,  # Historical trend for sea level
  Portland_Annual_Temp = portland_baseline_temp,  # Baseline temperature for Portland
  Belfast_Annual_Temp = belfast_baseline_temp,  # Baseline temperature for Belfast
  Moosehead_Annual_Temp = moosehead_baseline_temp,  # Baseline temperature for Moosehead
  Gardiner_Annual_Temp = gardiner_baseline_temp,  # Baseline temperature for Gardiner
  Augusta_Annual_Temp = augusta_baseline_temp,  # Baseline temperature for Augusta
  Annual_NAO = future_annual_nao,  # NAO for low climate change
  Civilian_Population_Millions = future_Civilian.Population..Millions.,  
  State_Population = future_state_population 
),

# Low Climate Change (SLR Low, Temp Low)
"Low_Climate" = data.frame(
  Year = future_years, 
  Mean_Sea_Level_m = low_slr,  # Low sea-level rise projection
  Portland_Annual_Temp = portland_low_temp,  # Low warming projection for Portland
  Belfast_Annual_Temp = belfast_low_temp,  # Low warming projection for Belfast
  Moosehead_Annual_Temp = moosehead_low_temp,  # Low warming projection for Moosehead
  Gardiner_Annual_Temp = gardiner_low_temp,  # Low warming projection for Gardiner
  Augusta_Annual_Temp = augusta_low_temp,  # Low warming projection for Augusta
  Annual_NAO = future_annual_nao,  # NAO for low climate change
  Civilian_Population_Millions = future_Civilian.Population..Millions.,  
  State_Population = future_state_population 
),

# Moderate Climate Change (SLR Moderate, Temp Moderate)
"Moderate_Climate" = data.frame(
  Year = future_years, 
  Mean_Sea_Level_m = moderate_slr,  # Moderate sea-level rise projection
  Portland_Annual_Temp = portland_moderate_temp,  # Moderate warming projection for Portland
  Belfast_Annual_Temp = belfast_moderate_temp,  # Moderate warming projection for Belfast
  Moosehead_Annual_Temp = moosehead_moderate_temp,  # Moderate warming projection for Moosehead
  Gardiner_Annual_Temp = gardiner_moderate_temp,  # Moderate warming projection for Gardiner
  Augusta_Annual_Temp = augusta_moderate_temp,  # Moderate warming projection for Augusta
  Annual_NAO = future_annual_nao,  # NAO for low climate change
  Civilian_Population_Millions = future_Civilian.Population..Millions.,  
  State_Population = future_state_population 
),

# Extreme Climate Change (SLR High, Temp High)
"Extreme_Climate" = data.frame(
  Year = future_years, 
  Mean_Sea_Level_m = high_slr,  # High sea-level rise projection
  Portland_Annual_Temp = portland_high_temp,  # Extreme warming projection for Portland
  Belfast_Annual_Temp = belfast_high_temp,  # Extreme warming projection for Belfast
  Moosehead_Annual_Temp = moosehead_high_temp,  # Extreme warming projection for Moosehead
  Gardiner_Annual_Temp = gardiner_high_temp,  # Extreme warming projection for Gardiner
  Augusta_Annual_Temp = augusta_high_temp,  # Extreme warming projection for Augusta
  Annual_NAO = future_annual_nao,  # NAO for low climate change
  Civilian_Population_Millions = future_Civilian.Population..Millions.,  
  State_Population = future_state_population
)
  
)

# Extract all required variables from the training dataset
required_vars <- colnames(interpolated_data)

# Function to add missing variables with the last observed value
fill_missing_with_last_value <- function(df_train, df_future) {
  for (var in required_vars) {
    if (!(var %in% colnames(df_future))) {
      # Get last observed (non-NA) value from df_train
      last_value <- tail(df_train[[var]][!is.na(df_train[[var]])], 1)
      
      # If there is no historical value (completely missing column), set to NA
      if (length(last_value) == 0) {
        last_value <- NA
      }
      
      # Assign the last observed value to all future years
      df_future[[var]] <- last_value
    }
  }
  return(df_future)
}

# Apply the function to all future scenarios
future_scenarios <- lapply(future_scenarios, function(df) {
  fill_missing_with_last_value(interpolated_data, df)
})
```

### Predict Species Results

```{r}
# Predict Landings (Total_weight) using environmental parameters and Maine Population
# sea level rise
# portland precipitation
# portland temperature
# NAO Index
# State Population

#predict US Consumption using civillian population and landings

# predict US exports from Maine using consumption, landings

# predict market value using GDP, Annual Change, Per capita, total_weight, consumption, and exports

# Predict total value or Maine Blue Economy using market value and total_weight
# Define full path for output directory
base_output_dir <- "C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Clean Data/Plots"

# Ensure base output directory exists
if (!dir.exists(base_output_dir)) {
  dir.create(base_output_dir, recursive = TRUE)
  cat("Created base directory:", base_output_dir, "\n")
}

# Load dataset
df <- interpolated_data

# Function to sanitize species names for file/folder use
sanitize_name <- function(name) {
  name %>%
    str_replace_all("[^A-Za-z0-9]", "_") %>%  # Replace special characters with underscores
    str_trim()  # Trim extra spaces
}

# Get sanitized species list
species_list <- unique(df$species)

# Iterate through each species
for (species_name in species_list) {
  
  cat("Processing:", species_name, "\n")

  # Create a sanitized directory name
  species_folder_name <- sanitize_name(species_name)
  species_output_dir <- file.path(base_output_dir, species_folder_name)
  
  if (!dir.exists(species_output_dir)) {
    dir.create(species_output_dir, recursive = TRUE)
  }

  # Filter data for the current species
  df_species <- df %>% filter(species == species_name)

  # Ensure enough data points exist for training
  if (nrow(df_species) < 10) {
    cat("Skipping", species_name, "- Not enough data\n")
    next
  }

  # 🔹 Train Landings Model
  landings_data <- df_species %>%
    dplyr::select(Total_Weight_kg, Mean_Sea_Level_m, Portland_Annual_Precip, 
                  Portland_Annual_Temp, Annual_NAO, State_Population)

  set.seed(123)
  trainIndex <- createDataPartition(landings_data$Total_Weight_kg, p = 0.8, list = FALSE)
  train <- landings_data[trainIndex, ]
  test <- landings_data[-trainIndex, ]

  rf_landings <- randomForest(Total_Weight_kg ~ ., data = train, ntree = 500)

  # 🔹 Train Consumption Model
  consumption_data <- df_species %>%
    dplyr::select(Fresh.And.Frozen..Pounds., Total_Weight_kg, Civilian.Population..Millions.)
  
  rf_consumption <- randomForest(Fresh.And.Frozen..Pounds. ~ Total_Weight_kg + Civilian.Population..Millions.,
                                 data = consumption_data, ntree = 500)

  # 🔹 Train Exports Model
  exports_data <- df_species %>%
    dplyr::select(Fishery_Exports, Total_Weight_kg, Fresh.And.Frozen..Pounds.)

  rf_exports <- randomForest(Fishery_Exports ~ Total_Weight_kg + Fresh.And.Frozen..Pounds., 
                             data = exports_data, ntree = 500)

  # 🔹 Train Market Value Model
  market_value_data <- df_species %>%
    dplyr::select(Avg_Market_Price, GDP..Billions.of.US..., Annual...Change, 
                  Per.Capita..US..., Total_Weight_kg, Fresh.And.Frozen..Pounds., Fishery_Exports)

  rf_market_value <- randomForest(Avg_Market_Price ~ ., data = market_value_data, ntree = 500)

  # 🔹 Train Blue Economy Model
  blue_economy_data <- df_species %>%
    dplyr::select(Total_Value, Avg_Market_Price, Total_Weight_kg)

  rf_blue_economy <- randomForest(Total_Value ~ Avg_Market_Price + Total_Weight_kg, 
                                  data = blue_economy_data, ntree = 500)

  # 🔹 Iterate Through Climate Scenarios
  scenario_results <- list()

  for (scenario_name in names(future_scenarios)) {
    
    future_df <- future_scenarios[[scenario_name]]
    
    # Predict Future Landings
    future_df$Predicted_Landings <- predict(rf_landings, newdata = future_df)
    future_df$Total_Weight_kg <- future_df$Predicted_Landings  
    
    # Predict Future Consumption
    future_df$Predicted_Consumption <- predict(rf_consumption, newdata = future_df)

    # Predict Future Exports
    future_df$Predicted_Exports <- predict(rf_exports, newdata = future_df)

    # Predict Future Market Value
    future_df$Predicted_Market_Value <- predict(rf_market_value, newdata = future_df)

    # Predict Future Blue Economy Value
    future_df$Predicted_Blue_Economy_Value <- predict(rf_blue_economy, newdata = future_df)

    # Store results
    scenario_results[[scenario_name]] <- future_df
  }

  # Combine results into a single dataframe
  results_df <- bind_rows(scenario_results, .id = "Scenario")

  # 🔹 Save Multiple Plots for Each Species in Its Own Directory
  plot_types <- list(
    "Total_Weight_kg" = "Maine Total Landings (kg)",
    "Predicted_Exports" = "Fishery Exports ($)",
    "Predicted_Market_Value" = "Market Value ($)",
    "Predicted_Blue_Economy_Value" = "Maine Blue Economy Value ($)"
  )

  for (col_name in names(plot_types)) {
    plot_title <- paste(plot_types[[col_name]], "Projection for", species_name)
    sanitized_col_name <- sanitize_name(col_name)
    plot_file <- file.path(species_output_dir, paste0(species_folder_name, "_", sanitized_col_name, "_Projection.png"))

    p <- ggplot(results_df, aes(x = Year, y = !!sym(col_name), color = Scenario)) +
      geom_line(size = 1.2) +
      ggtitle(plot_title) +
      xlab("Year") + ylab(plot_types[[col_name]]) +
      theme_minimal()

    ggsave(plot_file, plot = p, width = 8, height = 5)

    cat("Saved plot:", plot_file, "\n")
  }
}

```

## Validate Model

### Species

## Lobster by County
```{r}
lobster_validation <- read.csv("C:/Users/RDEL1VMM/Desktop/current projects/Maine_Blue_Economy/Available Data/LobByCntyMoZone_2020_2024.csv",
                   stringsAsFactors = FALSE, 
                   check.names = TRUE, 
                   skip = 0)  # Load all rows initially

# Set the first row as row names
colnames(lobster_validation) <- lobster_validation[1, ]

# Remove the first row from the dataset
lobster_validation <- lobster_validation[-1, ]

# Reset row indices
rownames(lobster_validation) <- NULL

# Convert Year column to numeric
lobster_validation$Year <- as.numeric(lobster_validation$Year)

# Convert numerical columns
lobster_validation$Lobster_Pounds <- as.numeric(lobster_validation$Pounds)
lobster_validation$Lobster_Value <- as.numeric(lobster_validation$Value)

# Filter to keep only the baseline scenario
# Step 1: Filter baseline scenario & relevant years
final_county_forecast_baseline <- final_county_forecast %>%
  filter(Scenario == "Baseline", Year >= 2020 & Year <= 2024) %>%
  select(Year, County, Pred_Lobster_Pounds, Pred_Lobster_Value)

# Step 2: Clean & Standardize County Names to Avoid Mismatches
final_county_forecast_baseline <- final_county_forecast_baseline %>%
  mutate(County = str_trim(County) %>% str_to_title())

lobster_validation <- lobster_validation %>%
  mutate(County = str_trim(County) %>% str_to_title())

# Step 3: Perform an Inner Join to Keep Only Matching Records
comparison_data <- inner_join(final_county_forecast_baseline, lobster_validation, by = c("Year", "County"))

# Check for unmatched records
unmatched_forecast <- setdiff(final_county_forecast_baseline$County, lobster_validation$County)
unmatched_validation <- setdiff(lobster_validation$County, final_county_forecast_baseline$County)

# Print any mismatches (if empty, then all counties matched correctly)
print(unmatched_forecast)  # Counties in forecast but not in validation
print(unmatched_validation)  # Counties in validation but not in forecast

# Check if any rows still contain NA values
summary(comparison_data)

# Ensure the merged data keeps both predicted and observed values as separate columns
comparison_pounds_data <- comparison_data %>%
  select(Year, County, Pred_Lobster_Pounds, Lobster_Pounds)

comparison_value_data <- comparison_data %>%
  select(Year, County, Pred_Lobster_Value, Lobster_Value)

# Unique counties
counties <- unique(comparison_pounds_long$County)

for (county in counties) {
  
  county_data <- comparison_pounds_long %>% filter(County == county)
  county_value_data <- comparison_value_long %>% filter(County == county)

  # Assign colors and linetypes
  unique_types <- unique(county_data$Type)
  scenario_colors <- setNames(rainbow(length(unique_types)), unique_types) 
  scenario_linetypes <- setNames(rep("dashed", length(unique_types)), unique_types)

  # Ensure "Observed" is black and solid
  scenario_colors["Observed"] <- "black"
  scenario_linetypes["Observed"] <- "solid"
}

# Compute error metrics for Lobster Pounds
mae_pounds <- mae(comparison_data$Lobster_Pounds, comparison_data$Pred_Lobster_Pounds)
mse_pounds <- mse(comparison_data$Lobster_Pounds, comparison_data$Pred_Lobster_Pounds)
rmse_pounds <- rmse(comparison_data$Lobster_Pounds, comparison_data$Pred_Lobster_Pounds)
r2_pounds <- cor(comparison_data$Lobster_Pounds, comparison_data$Pred_Lobster_Pounds, use = "complete.obs")^2

# Compute error metrics for Lobster Value
mae_value <- mae(comparison_data$Lobster_Value, comparison_data$Pred_Lobster_Value)
mse_value <- mse(comparison_data$Lobster_Value, comparison_data$Pred_Lobster_Value)
rmse_value <- rmse(comparison_data$Lobster_Value, comparison_data$Pred_Lobster_Value)
r2_value <- cor(comparison_data$Lobster_Value, comparison_data$Pred_Lobster_Value, use = "complete.obs")^2

# Print Error Metrics
cat("Lobster Pounds Prediction Evaluation:\n")
cat("MAE:", mae_pounds, "\n")
cat("MSE:", mse_pounds, "\n")
cat("RMSE:", rmse_pounds, "\n")
cat("R²:", r2_pounds, "\n\n")

cat("Lobster Value Prediction Evaluation:\n")
cat("MAE:", mae_value, "\n")
cat("MSE:", mse_value, "\n")
cat("RMSE:", rmse_value, "\n")
cat("R²:", r2_value, "\n")
```

